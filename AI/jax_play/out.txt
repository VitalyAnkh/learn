// -----// IR Dump After ReconcileUnrealizedCasts (reconcile-unrealized-casts) //----- //
#map = affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>
module attributes {gpu.container_module} {
  func.func @matmul_memref(%arg0: memref<512x512xf32>, %arg1: memref<512x512xf32>, %arg2: memref<512x512xf32>) attributes {llvm.emit_c_interface} {
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %c16 = arith.constant 16 : index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%c16, %c32, %c1) threads in (%c32, %c16, %c1)  args(%c32 : index, %c0 : index, %c16 : index, %c1 : index, %c512 : index, %arg0 : memref<512x512xf32>, %arg1 : memref<512x512xf32>, %arg2 : memref<512x512xf32>)
    return
  }
  gpu.module @matmul_memref_kernel {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %block_id_x = gpu.block_id  x
      %block_id_y = gpu.block_id  y
      %block_id_z = gpu.block_id  z
      %thread_id_x = gpu.thread_id  x
      %thread_id_y = gpu.thread_id  y
      %thread_id_z = gpu.thread_id  z
      %grid_dim_x = gpu.grid_dim  x
      %grid_dim_y = gpu.grid_dim  y
      %grid_dim_z = gpu.grid_dim  z
      %block_dim_x = gpu.block_dim  x
      %block_dim_y = gpu.block_dim  y
      %block_dim_z = gpu.block_dim  z
      %0 = affine.apply #map(%block_id_x)[%arg0, %arg1]
      %1 = affine.apply #map(%block_id_y)[%arg2, %arg1]
      %2 = affine.apply #map(%thread_id_x)[%arg3, %arg1]
      %3 = affine.apply #map(%thread_id_y)[%arg3, %arg1]
      %4 = arith.addi %2, %0 : index
      %5 = arith.addi %3, %1 : index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%6: index):  // 2 preds: ^bb0, ^bb2
      %7 = arith.cmpi slt, %6, %arg4 : index
      llvm.cond_br %7, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %8 = memref.load %arg5[%4, %6] : memref<512x512xf32>
      %9 = memref.load %arg6[%6, %5] : memref<512x512xf32>
      %10 = memref.load %arg7[%4, %5] : memref<512x512xf32>
      %11 = arith.mulf %8, %9 : f32
      %12 = arith.addf %10, %11 : f32
      memref.store %12, %arg7[%4, %5] : memref<512x512xf32>
      %13 = arith.addi %6, %arg3 : index
      cf.br ^bb1(%13 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After LLVMRequestCWrappers (llvm-request-c-wrappers) //----- //
func.func @matmul_memref(%arg0: memref<512x512xf32>, %arg1: memref<512x512xf32>, %arg2: memref<512x512xf32>) attributes {llvm.emit_c_interface} {
  %c0 = arith.constant 0 : index
  %c512 = arith.constant 512 : index
  %c1 = arith.constant 1 : index
  %c32 = arith.constant 32 : index
  %c16 = arith.constant 16 : index
  gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%c16, %c32, %c1) threads in (%c32, %c16, %c1)  args(%c32 : index, %c0 : index, %c16 : index, %c1 : index, %c512 : index, %arg0 : memref<512x512xf32>, %arg1 : memref<512x512xf32>, %arg2 : memref<512x512xf32>)
  return
}

// -----// IR Dump After ExpandStridedMetadata (expand-strided-metadata) //----- //
gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
  %block_id_x = gpu.block_id  x
  %block_id_y = gpu.block_id  y
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %0 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%block_id_x)[%arg0, %arg1]
  %1 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%block_id_y)[%arg2, %arg1]
  %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%thread_id_x)[%arg3, %arg1]
  %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%thread_id_y)[%arg3, %arg1]
  %4 = arith.addi %2, %0 : index
  %5 = arith.addi %3, %1 : index
  cf.br ^bb1(%arg1 : index)
^bb1(%6: index):  // 2 preds: ^bb0, ^bb2
  %7 = arith.cmpi slt, %6, %arg4 : index
  llvm.cond_br %7, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %8 = memref.load %arg5[%4, %6] : memref<512x512xf32>
  %9 = memref.load %arg6[%6, %5] : memref<512x512xf32>
  %10 = memref.load %arg7[%4, %5] : memref<512x512xf32>
  %11 = arith.mulf %8, %9 : f32
  %12 = arith.addf %10, %11 : f32
  memref.store %12, %arg7[%4, %5] : memref<512x512xf32>
  %13 = arith.addi %6, %arg3 : index
  cf.br ^bb1(%13 : index)
^bb3:  // pred: ^bb1
  gpu.return
}

// -----// IR Dump After ReconcileUnrealizedCasts (reconcile-unrealized-casts) //----- //
gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
  %block_id_x = gpu.block_id  x
  %block_id_y = gpu.block_id  y
  %thread_id_x = gpu.thread_id  x
  %thread_id_y = gpu.thread_id  y
  %0 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%block_id_x)[%arg0, %arg1]
  %1 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%block_id_y)[%arg2, %arg1]
  %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%thread_id_x)[%arg3, %arg1]
  %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%thread_id_y)[%arg3, %arg1]
  %4 = arith.addi %2, %0 : index
  %5 = arith.addi %3, %1 : index
  cf.br ^bb1(%arg1 : index)
^bb1(%6: index):  // 2 preds: ^bb0, ^bb2
  %7 = arith.cmpi slt, %6, %arg4 : index
  llvm.cond_br %7, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %8 = memref.load %arg5[%4, %6] : memref<512x512xf32>
  %9 = memref.load %arg6[%6, %5] : memref<512x512xf32>
  %10 = memref.load %arg7[%4, %5] : memref<512x512xf32>
  %11 = arith.mulf %8, %9 : f32
  %12 = arith.addf %10, %11 : f32
  memref.store %12, %arg7[%4, %5] : memref<512x512xf32>
  %13 = arith.addi %6, %arg3 : index
  cf.br ^bb1(%13 : index)
^bb3:  // pred: ^bb1
  gpu.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#map = affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>
module attributes {gpu.container_module} {
  func.func @matmul_memref(%arg0: memref<512x512xf32>, %arg1: memref<512x512xf32>, %arg2: memref<512x512xf32>) attributes {llvm.emit_c_interface} {
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %c16 = arith.constant 16 : index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%c16, %c32, %c1) threads in (%c32, %c16, %c1)  args(%c32 : index, %c0 : index, %c16 : index, %c1 : index, %c512 : index, %arg0 : memref<512x512xf32>, %arg1 : memref<512x512xf32>, %arg2 : memref<512x512xf32>)
    return
  }
  gpu.module @matmul_memref_kernel {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %block_id_x = gpu.block_id  x
      %block_id_y = gpu.block_id  y
      %thread_id_x = gpu.thread_id  x
      %thread_id_y = gpu.thread_id  y
      %0 = affine.apply #map(%block_id_x)[%arg0, %arg1]
      %1 = affine.apply #map(%block_id_y)[%arg2, %arg1]
      %2 = affine.apply #map(%thread_id_x)[%arg3, %arg1]
      %3 = affine.apply #map(%thread_id_y)[%arg3, %arg1]
      %4 = arith.addi %2, %0 : index
      %5 = arith.addi %3, %1 : index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%6: index):  // 2 preds: ^bb0, ^bb2
      %7 = arith.cmpi slt, %6, %arg4 : index
      llvm.cond_br %7, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %8 = memref.load %arg5[%4, %6] : memref<512x512xf32>
      %9 = memref.load %arg6[%6, %5] : memref<512x512xf32>
      %10 = memref.load %arg7[%4, %5] : memref<512x512xf32>
      %11 = arith.mulf %8, %9 : f32
      %12 = arith.addf %10, %11 : f32
      memref.store %12, %arg7[%4, %5] : memref<512x512xf32>
      %13 = arith.addi %6, %arg3 : index
      cf.br ^bb1(%13 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
module attributes {gpu.container_module} {
  func.func @matmul_memref(%arg0: memref<512x512xf32>, %arg1: memref<512x512xf32>, %arg2: memref<512x512xf32>) attributes {llvm.emit_c_interface} {
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %c16 = arith.constant 16 : index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%c16, %c32, %c1) threads in (%c32, %c16, %c1)  args(%c32 : index, %c0 : index, %c16 : index, %c1 : index, %c512 : index, %arg0 : memref<512x512xf32>, %arg1 : memref<512x512xf32>, %arg2 : memref<512x512xf32>)
    return
  }
  gpu.module @matmul_memref_kernel {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %block_id_x = gpu.block_id  x
      %block_id_y = gpu.block_id  y
      %thread_id_x = gpu.thread_id  x
      %thread_id_y = gpu.thread_id  y
      %0 = arith.muli %block_id_x, %arg0 : index
      %1 = arith.addi %0, %arg1 : index
      %2 = arith.muli %block_id_y, %arg2 : index
      %3 = arith.addi %2, %arg1 : index
      %4 = arith.muli %thread_id_x, %arg3 : index
      %5 = arith.addi %4, %arg1 : index
      %6 = arith.muli %thread_id_y, %arg3 : index
      %7 = arith.addi %6, %arg1 : index
      %8 = arith.addi %5, %1 : index
      %9 = arith.addi %7, %3 : index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%10: index):  // 2 preds: ^bb0, ^bb2
      %11 = arith.cmpi slt, %10, %arg4 : index
      llvm.cond_br %11, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %12 = memref.load %arg5[%8, %10] : memref<512x512xf32>
      %13 = memref.load %arg6[%10, %9] : memref<512x512xf32>
      %14 = memref.load %arg7[%8, %9] : memref<512x512xf32>
      %15 = arith.mulf %12, %13 : f32
      %16 = arith.addf %14, %15 : f32
      memref.store %16, %arg7[%8, %9] : memref<512x512xf32>
      %17 = arith.addi %10, %arg3 : index
      cf.br ^bb1(%17 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
module attributes {gpu.container_module} {
  func.func @matmul_memref(%arg0: memref<512x512xf32>, %arg1: memref<512x512xf32>, %arg2: memref<512x512xf32>) attributes {llvm.emit_c_interface} {
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %c16 = arith.constant 16 : index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%c16, %c32, %c1) threads in (%c32, %c16, %c1)  args(%c32 : index, %c0 : index, %c16 : index, %c1 : index, %c512 : index, %arg0 : memref<512x512xf32>, %arg1 : memref<512x512xf32>, %arg2 : memref<512x512xf32>)
    return
  }
  gpu.module @matmul_memref_kernel {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %block_id_x = gpu.block_id  x
      %block_id_y = gpu.block_id  y
      %thread_id_x = gpu.thread_id  x
      %thread_id_y = gpu.thread_id  y
      %0 = arith.muli %block_id_x, %arg0 : index
      %1 = arith.addi %0, %arg1 : index
      %2 = arith.muli %block_id_y, %arg2 : index
      %3 = arith.addi %2, %arg1 : index
      %4 = arith.muli %thread_id_x, %arg3 : index
      %5 = arith.addi %4, %arg1 : index
      %6 = arith.muli %thread_id_y, %arg3 : index
      %7 = arith.addi %6, %arg1 : index
      %8 = arith.addi %5, %1 : index
      %9 = arith.addi %7, %3 : index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%10: index):  // 2 preds: ^bb0, ^bb2
      %11 = arith.cmpi slt, %10, %arg4 : index
      llvm.cond_br %11, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %12 = memref.load %arg5[%8, %10] : memref<512x512xf32>
      %13 = memref.load %arg6[%10, %9] : memref<512x512xf32>
      %14 = memref.load %arg7[%8, %9] : memref<512x512xf32>
      %15 = arith.mulf %12, %13 : f32
      %16 = arith.addf %14, %15 : f32
      memref.store %16, %arg7[%8, %9] : memref<512x512xf32>
      %17 = arith.addi %10, %arg3 : index
      cf.br ^bb1(%17 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After ConvertControlFlowToLLVMPass (convert-cf-to-llvm) //----- //
module attributes {gpu.container_module} {
  func.func @matmul_memref(%arg0: memref<512x512xf32>, %arg1: memref<512x512xf32>, %arg2: memref<512x512xf32>) attributes {llvm.emit_c_interface} {
    %c0 = arith.constant 0 : index
    %c512 = arith.constant 512 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %c16 = arith.constant 16 : index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%c16, %c32, %c1) threads in (%c32, %c16, %c1)  args(%c32 : index, %c0 : index, %c16 : index, %c1 : index, %c512 : index, %arg0 : memref<512x512xf32>, %arg1 : memref<512x512xf32>, %arg2 : memref<512x512xf32>)
    return
  }
  gpu.module @matmul_memref_kernel {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %block_id_x = gpu.block_id  x
      %block_id_y = gpu.block_id  y
      %thread_id_x = gpu.thread_id  x
      %thread_id_y = gpu.thread_id  y
      %0 = arith.muli %block_id_x, %arg0 : index
      %1 = arith.addi %0, %arg1 : index
      %2 = arith.muli %block_id_y, %arg2 : index
      %3 = arith.addi %2, %arg1 : index
      %4 = arith.muli %thread_id_x, %arg3 : index
      %5 = arith.addi %4, %arg1 : index
      %6 = arith.muli %thread_id_y, %arg3 : index
      %7 = arith.addi %6, %arg1 : index
      %8 = arith.addi %5, %1 : index
      %9 = arith.addi %7, %3 : index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%10: index):  // 2 preds: ^bb0, ^bb2
      %11 = arith.cmpi slt, %10, %arg4 : index
      llvm.cond_br %11, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %12 = memref.load %arg5[%8, %10] : memref<512x512xf32>
      %13 = memref.load %arg6[%10, %9] : memref<512x512xf32>
      %14 = memref.load %arg7[%8, %9] : memref<512x512xf32>
      %15 = arith.mulf %12, %13 : f32
      %16 = arith.addf %14, %15 : f32
      memref.store %16, %arg7[%8, %9] : memref<512x512xf32>
      %17 = arith.addi %10, %arg3 : index
      cf.br ^bb1(%17 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After ArithToLLVMConversionPass (convert-arith-to-llvm) //----- //
module attributes {gpu.container_module} {
  func.func @matmul_memref(%arg0: memref<512x512xf32>, %arg1: memref<512x512xf32>, %arg2: memref<512x512xf32>) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = builtin.unrealized_conversion_cast %0 : i64 to index
    %2 = llvm.mlir.constant(512 : index) : i64
    %3 = builtin.unrealized_conversion_cast %2 : i64 to index
    %4 = llvm.mlir.constant(1 : index) : i64
    %5 = builtin.unrealized_conversion_cast %4 : i64 to index
    %6 = llvm.mlir.constant(32 : index) : i64
    %7 = builtin.unrealized_conversion_cast %6 : i64 to index
    %8 = llvm.mlir.constant(16 : index) : i64
    %9 = builtin.unrealized_conversion_cast %8 : i64 to index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%9, %7, %5) threads in (%7, %9, %5)  args(%7 : index, %1 : index, %9 : index, %5 : index, %3 : index, %arg0 : memref<512x512xf32>, %arg1 : memref<512x512xf32>, %arg2 : memref<512x512xf32>)
    return
  }
  gpu.module @matmul_memref_kernel {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %0 = builtin.unrealized_conversion_cast %arg4 : index to i64
      %1 = builtin.unrealized_conversion_cast %arg3 : index to i64
      %2 = builtin.unrealized_conversion_cast %arg2 : index to i64
      %3 = builtin.unrealized_conversion_cast %arg1 : index to i64
      %4 = builtin.unrealized_conversion_cast %arg0 : index to i64
      %block_id_x = gpu.block_id  x
      %5 = builtin.unrealized_conversion_cast %block_id_x : index to i64
      %block_id_y = gpu.block_id  y
      %6 = builtin.unrealized_conversion_cast %block_id_y : index to i64
      %thread_id_x = gpu.thread_id  x
      %7 = builtin.unrealized_conversion_cast %thread_id_x : index to i64
      %thread_id_y = gpu.thread_id  y
      %8 = builtin.unrealized_conversion_cast %thread_id_y : index to i64
      %9 = llvm.mul %5, %4 : i64
      %10 = llvm.add %9, %3 : i64
      %11 = llvm.mul %6, %2 : i64
      %12 = llvm.add %11, %3 : i64
      %13 = llvm.mul %7, %1 : i64
      %14 = llvm.add %13, %3 : i64
      %15 = llvm.mul %8, %1 : i64
      %16 = llvm.add %15, %3 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = builtin.unrealized_conversion_cast %17 : i64 to index
      %19 = llvm.add %16, %12 : i64
      %20 = builtin.unrealized_conversion_cast %19 : i64 to index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%21: index):  // 2 preds: ^bb0, ^bb2
      %22 = builtin.unrealized_conversion_cast %21 : index to i64
      %23 = llvm.icmp "slt" %22, %0 : i64
      llvm.cond_br %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %24 = memref.load %arg5[%18, %21] : memref<512x512xf32>
      %25 = memref.load %arg6[%21, %20] : memref<512x512xf32>
      %26 = memref.load %arg7[%18, %20] : memref<512x512xf32>
      %27 = llvm.fmul %24, %25  : f32
      %28 = llvm.fadd %26, %27  : f32
      memref.store %28, %arg7[%18, %20] : memref<512x512xf32>
      %29 = llvm.add %22, %1 : i64
      %30 = builtin.unrealized_conversion_cast %29 : i64 to index
      cf.br ^bb1(%30 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After ConvertMathToLLVMPass (convert-math-to-llvm) //----- //
module attributes {gpu.container_module} {
  func.func @matmul_memref(%arg0: memref<512x512xf32>, %arg1: memref<512x512xf32>, %arg2: memref<512x512xf32>) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = builtin.unrealized_conversion_cast %0 : i64 to index
    %2 = llvm.mlir.constant(512 : index) : i64
    %3 = builtin.unrealized_conversion_cast %2 : i64 to index
    %4 = llvm.mlir.constant(1 : index) : i64
    %5 = builtin.unrealized_conversion_cast %4 : i64 to index
    %6 = llvm.mlir.constant(32 : index) : i64
    %7 = builtin.unrealized_conversion_cast %6 : i64 to index
    %8 = llvm.mlir.constant(16 : index) : i64
    %9 = builtin.unrealized_conversion_cast %8 : i64 to index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%9, %7, %5) threads in (%7, %9, %5)  args(%7 : index, %1 : index, %9 : index, %5 : index, %3 : index, %arg0 : memref<512x512xf32>, %arg1 : memref<512x512xf32>, %arg2 : memref<512x512xf32>)
    return
  }
  gpu.module @matmul_memref_kernel {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %0 = builtin.unrealized_conversion_cast %arg4 : index to i64
      %1 = builtin.unrealized_conversion_cast %arg3 : index to i64
      %2 = builtin.unrealized_conversion_cast %arg2 : index to i64
      %3 = builtin.unrealized_conversion_cast %arg1 : index to i64
      %4 = builtin.unrealized_conversion_cast %arg0 : index to i64
      %block_id_x = gpu.block_id  x
      %5 = builtin.unrealized_conversion_cast %block_id_x : index to i64
      %block_id_y = gpu.block_id  y
      %6 = builtin.unrealized_conversion_cast %block_id_y : index to i64
      %thread_id_x = gpu.thread_id  x
      %7 = builtin.unrealized_conversion_cast %thread_id_x : index to i64
      %thread_id_y = gpu.thread_id  y
      %8 = builtin.unrealized_conversion_cast %thread_id_y : index to i64
      %9 = llvm.mul %5, %4 : i64
      %10 = llvm.add %9, %3 : i64
      %11 = llvm.mul %6, %2 : i64
      %12 = llvm.add %11, %3 : i64
      %13 = llvm.mul %7, %1 : i64
      %14 = llvm.add %13, %3 : i64
      %15 = llvm.mul %8, %1 : i64
      %16 = llvm.add %15, %3 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = builtin.unrealized_conversion_cast %17 : i64 to index
      %19 = llvm.add %16, %12 : i64
      %20 = builtin.unrealized_conversion_cast %19 : i64 to index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%21: index):  // 2 preds: ^bb0, ^bb2
      %22 = builtin.unrealized_conversion_cast %21 : index to i64
      %23 = llvm.icmp "slt" %22, %0 : i64
      llvm.cond_br %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %24 = memref.load %arg5[%18, %21] : memref<512x512xf32>
      %25 = memref.load %arg6[%21, %20] : memref<512x512xf32>
      %26 = memref.load %arg7[%18, %20] : memref<512x512xf32>
      %27 = llvm.fmul %24, %25  : f32
      %28 = llvm.fadd %26, %27  : f32
      memref.store %28, %arg7[%18, %20] : memref<512x512xf32>
      %29 = llvm.add %22, %1 : i64
      %30 = builtin.unrealized_conversion_cast %29 : i64 to index
      cf.br ^bb1(%30 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After NormalizeMemRefs (normalize-memrefs) //----- //
module attributes {gpu.container_module} {
  func.func @matmul_memref(%arg0: memref<512x512xf32>, %arg1: memref<512x512xf32>, %arg2: memref<512x512xf32>) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = builtin.unrealized_conversion_cast %0 : i64 to index
    %2 = llvm.mlir.constant(512 : index) : i64
    %3 = builtin.unrealized_conversion_cast %2 : i64 to index
    %4 = llvm.mlir.constant(1 : index) : i64
    %5 = builtin.unrealized_conversion_cast %4 : i64 to index
    %6 = llvm.mlir.constant(32 : index) : i64
    %7 = builtin.unrealized_conversion_cast %6 : i64 to index
    %8 = llvm.mlir.constant(16 : index) : i64
    %9 = builtin.unrealized_conversion_cast %8 : i64 to index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%9, %7, %5) threads in (%7, %9, %5)  args(%7 : index, %1 : index, %9 : index, %5 : index, %3 : index, %arg0 : memref<512x512xf32>, %arg1 : memref<512x512xf32>, %arg2 : memref<512x512xf32>)
    return
  }
  gpu.module @matmul_memref_kernel {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %0 = builtin.unrealized_conversion_cast %arg4 : index to i64
      %1 = builtin.unrealized_conversion_cast %arg3 : index to i64
      %2 = builtin.unrealized_conversion_cast %arg2 : index to i64
      %3 = builtin.unrealized_conversion_cast %arg1 : index to i64
      %4 = builtin.unrealized_conversion_cast %arg0 : index to i64
      %block_id_x = gpu.block_id  x
      %5 = builtin.unrealized_conversion_cast %block_id_x : index to i64
      %block_id_y = gpu.block_id  y
      %6 = builtin.unrealized_conversion_cast %block_id_y : index to i64
      %thread_id_x = gpu.thread_id  x
      %7 = builtin.unrealized_conversion_cast %thread_id_x : index to i64
      %thread_id_y = gpu.thread_id  y
      %8 = builtin.unrealized_conversion_cast %thread_id_y : index to i64
      %9 = llvm.mul %5, %4 : i64
      %10 = llvm.add %9, %3 : i64
      %11 = llvm.mul %6, %2 : i64
      %12 = llvm.add %11, %3 : i64
      %13 = llvm.mul %7, %1 : i64
      %14 = llvm.add %13, %3 : i64
      %15 = llvm.mul %8, %1 : i64
      %16 = llvm.add %15, %3 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = builtin.unrealized_conversion_cast %17 : i64 to index
      %19 = llvm.add %16, %12 : i64
      %20 = builtin.unrealized_conversion_cast %19 : i64 to index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%21: index):  // 2 preds: ^bb0, ^bb2
      %22 = builtin.unrealized_conversion_cast %21 : index to i64
      %23 = llvm.icmp "slt" %22, %0 : i64
      llvm.cond_br %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %24 = memref.load %arg5[%18, %21] : memref<512x512xf32>
      %25 = memref.load %arg6[%21, %20] : memref<512x512xf32>
      %26 = memref.load %arg7[%18, %20] : memref<512x512xf32>
      %27 = llvm.fmul %24, %25  : f32
      %28 = llvm.fadd %26, %27  : f32
      memref.store %28, %arg7[%18, %20] : memref<512x512xf32>
      %29 = llvm.add %22, %1 : i64
      %30 = builtin.unrealized_conversion_cast %29 : i64 to index
      cf.br ^bb1(%30 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After ExpandOps (memref-expand) //----- //
module attributes {gpu.container_module} {
  func.func @matmul_memref(%arg0: memref<512x512xf32>, %arg1: memref<512x512xf32>, %arg2: memref<512x512xf32>) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = builtin.unrealized_conversion_cast %0 : i64 to index
    %2 = llvm.mlir.constant(512 : index) : i64
    %3 = builtin.unrealized_conversion_cast %2 : i64 to index
    %4 = llvm.mlir.constant(1 : index) : i64
    %5 = builtin.unrealized_conversion_cast %4 : i64 to index
    %6 = llvm.mlir.constant(32 : index) : i64
    %7 = builtin.unrealized_conversion_cast %6 : i64 to index
    %8 = llvm.mlir.constant(16 : index) : i64
    %9 = builtin.unrealized_conversion_cast %8 : i64 to index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%9, %7, %5) threads in (%7, %9, %5)  args(%7 : index, %1 : index, %9 : index, %5 : index, %3 : index, %arg0 : memref<512x512xf32>, %arg1 : memref<512x512xf32>, %arg2 : memref<512x512xf32>)
    return
  }
  gpu.module @matmul_memref_kernel {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %0 = builtin.unrealized_conversion_cast %arg4 : index to i64
      %1 = builtin.unrealized_conversion_cast %arg3 : index to i64
      %2 = builtin.unrealized_conversion_cast %arg2 : index to i64
      %3 = builtin.unrealized_conversion_cast %arg1 : index to i64
      %4 = builtin.unrealized_conversion_cast %arg0 : index to i64
      %block_id_x = gpu.block_id  x
      %5 = builtin.unrealized_conversion_cast %block_id_x : index to i64
      %block_id_y = gpu.block_id  y
      %6 = builtin.unrealized_conversion_cast %block_id_y : index to i64
      %thread_id_x = gpu.thread_id  x
      %7 = builtin.unrealized_conversion_cast %thread_id_x : index to i64
      %thread_id_y = gpu.thread_id  y
      %8 = builtin.unrealized_conversion_cast %thread_id_y : index to i64
      %9 = llvm.mul %5, %4 : i64
      %10 = llvm.add %9, %3 : i64
      %11 = llvm.mul %6, %2 : i64
      %12 = llvm.add %11, %3 : i64
      %13 = llvm.mul %7, %1 : i64
      %14 = llvm.add %13, %3 : i64
      %15 = llvm.mul %8, %1 : i64
      %16 = llvm.add %15, %3 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = builtin.unrealized_conversion_cast %17 : i64 to index
      %19 = llvm.add %16, %12 : i64
      %20 = builtin.unrealized_conversion_cast %19 : i64 to index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%21: index):  // 2 preds: ^bb0, ^bb2
      %22 = builtin.unrealized_conversion_cast %21 : index to i64
      %23 = llvm.icmp "slt" %22, %0 : i64
      llvm.cond_br %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %24 = memref.load %arg5[%18, %21] : memref<512x512xf32>
      %25 = memref.load %arg6[%21, %20] : memref<512x512xf32>
      %26 = memref.load %arg7[%18, %20] : memref<512x512xf32>
      %27 = llvm.fmul %24, %25  : f32
      %28 = llvm.fadd %26, %27  : f32
      memref.store %28, %arg7[%18, %20] : memref<512x512xf32>
      %29 = llvm.add %22, %1 : i64
      %30 = builtin.unrealized_conversion_cast %29 : i64 to index
      cf.br ^bb1(%30 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After GpuDecomposeMemrefsPass (gpu-decompose-memrefs) //----- //
module attributes {gpu.container_module} {
  func.func @matmul_memref(%arg0: memref<512x512xf32>, %arg1: memref<512x512xf32>, %arg2: memref<512x512xf32>) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(16 : index) : i64
    %1 = llvm.mlir.constant(32 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i64
    %3 = llvm.mlir.constant(512 : index) : i64
    %4 = llvm.mlir.constant(0 : index) : i64
    %5 = builtin.unrealized_conversion_cast %4 : i64 to index
    %6 = builtin.unrealized_conversion_cast %3 : i64 to index
    %7 = builtin.unrealized_conversion_cast %2 : i64 to index
    %8 = builtin.unrealized_conversion_cast %1 : i64 to index
    %9 = builtin.unrealized_conversion_cast %0 : i64 to index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%9, %8, %7) threads in (%8, %9, %7)  args(%8 : index, %5 : index, %9 : index, %7 : index, %6 : index, %arg0 : memref<512x512xf32>, %arg1 : memref<512x512xf32>, %arg2 : memref<512x512xf32>)
    return
  }
  gpu.module @matmul_memref_kernel {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %0 = builtin.unrealized_conversion_cast %arg4 : index to i64
      %1 = builtin.unrealized_conversion_cast %arg3 : index to i64
      %2 = builtin.unrealized_conversion_cast %arg2 : index to i64
      %3 = builtin.unrealized_conversion_cast %arg1 : index to i64
      %4 = builtin.unrealized_conversion_cast %arg0 : index to i64
      %block_id_x = gpu.block_id  x
      %5 = builtin.unrealized_conversion_cast %block_id_x : index to i64
      %block_id_y = gpu.block_id  y
      %6 = builtin.unrealized_conversion_cast %block_id_y : index to i64
      %thread_id_x = gpu.thread_id  x
      %7 = builtin.unrealized_conversion_cast %thread_id_x : index to i64
      %thread_id_y = gpu.thread_id  y
      %8 = builtin.unrealized_conversion_cast %thread_id_y : index to i64
      %9 = llvm.mul %5, %4 : i64
      %10 = llvm.add %9, %3 : i64
      %11 = llvm.mul %6, %2 : i64
      %12 = llvm.add %11, %3 : i64
      %13 = llvm.mul %7, %1 : i64
      %14 = llvm.add %13, %3 : i64
      %15 = llvm.mul %8, %1 : i64
      %16 = llvm.add %15, %3 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = builtin.unrealized_conversion_cast %17 : i64 to index
      %19 = llvm.add %16, %12 : i64
      %20 = builtin.unrealized_conversion_cast %19 : i64 to index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%21: index):  // 2 preds: ^bb0, ^bb2
      %22 = builtin.unrealized_conversion_cast %21 : index to i64
      %23 = llvm.icmp "slt" %22, %0 : i64
      llvm.cond_br %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %24 = memref.load %arg5[%18, %21] : memref<512x512xf32>
      %25 = memref.load %arg6[%21, %20] : memref<512x512xf32>
      %26 = memref.load %arg7[%18, %20] : memref<512x512xf32>
      %27 = llvm.fmul %24, %25  : f32
      %28 = llvm.fadd %26, %27  : f32
      memref.store %28, %arg7[%18, %20] : memref<512x512xf32>
      %29 = llvm.add %22, %1 : i64
      %30 = builtin.unrealized_conversion_cast %29 : i64 to index
      cf.br ^bb1(%30 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After ConvertFuncToLLVMPass (convert-func-to-llvm) //----- //
module attributes {gpu.container_module} {
  llvm.func @matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64, %arg14: !llvm.ptr, %arg15: !llvm.ptr, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: i64) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.insertvalue %arg14, %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.insertvalue %arg15, %1[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.insertvalue %arg16, %2[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.insertvalue %arg17, %3[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.insertvalue %arg19, %4[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.insertvalue %arg18, %5[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg20, %6[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = builtin.unrealized_conversion_cast %7 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %9 = builtin.unrealized_conversion_cast %8 : memref<512x512xf32> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %10 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %11 = llvm.insertvalue %arg7, %10[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg8, %11[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.insertvalue %arg9, %12[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.insertvalue %arg10, %13[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg12, %14[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %arg11, %15[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %arg13, %16[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = builtin.unrealized_conversion_cast %17 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %19 = builtin.unrealized_conversion_cast %18 : memref<512x512xf32> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %20 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %21 = llvm.insertvalue %arg0, %20[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.insertvalue %arg1, %21[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.insertvalue %arg2, %22[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %24 = llvm.insertvalue %arg3, %23[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %25 = llvm.insertvalue %arg5, %24[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %26 = llvm.insertvalue %arg4, %25[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %27 = llvm.insertvalue %arg6, %26[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %28 = builtin.unrealized_conversion_cast %27 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %29 = builtin.unrealized_conversion_cast %28 : memref<512x512xf32> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %30 = llvm.mlir.constant(16 : index) : i64
    %31 = llvm.mlir.constant(32 : index) : i64
    %32 = llvm.mlir.constant(1 : index) : i64
    %33 = llvm.mlir.constant(512 : index) : i64
    %34 = llvm.mlir.constant(0 : index) : i64
    %35 = builtin.unrealized_conversion_cast %34 : i64 to index
    %36 = builtin.unrealized_conversion_cast %33 : i64 to index
    %37 = builtin.unrealized_conversion_cast %32 : i64 to index
    %38 = builtin.unrealized_conversion_cast %31 : i64 to index
    %39 = builtin.unrealized_conversion_cast %30 : i64 to index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%39, %38, %37) threads in (%38, %39, %37)  args(%38 : index, %35 : index, %39 : index, %37 : index, %36 : index, %28 : memref<512x512xf32>, %18 : memref<512x512xf32>, %8 : memref<512x512xf32>)
    llvm.return
  }
  llvm.func @_mlir_ciface_matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %17 = llvm.extractvalue %16[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.extractvalue %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.extractvalue %16[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.extractvalue %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.extractvalue %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.extractvalue %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.extractvalue %16[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.call @matmul_memref(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15, %17, %18, %19, %20, %21, %22, %23) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> ()
    llvm.return
  }
  gpu.module @matmul_memref_kernel {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %0 = builtin.unrealized_conversion_cast %arg4 : index to i64
      %1 = builtin.unrealized_conversion_cast %arg3 : index to i64
      %2 = builtin.unrealized_conversion_cast %arg2 : index to i64
      %3 = builtin.unrealized_conversion_cast %arg1 : index to i64
      %4 = builtin.unrealized_conversion_cast %arg0 : index to i64
      %block_id_x = gpu.block_id  x
      %5 = builtin.unrealized_conversion_cast %block_id_x : index to i64
      %block_id_y = gpu.block_id  y
      %6 = builtin.unrealized_conversion_cast %block_id_y : index to i64
      %thread_id_x = gpu.thread_id  x
      %7 = builtin.unrealized_conversion_cast %thread_id_x : index to i64
      %thread_id_y = gpu.thread_id  y
      %8 = builtin.unrealized_conversion_cast %thread_id_y : index to i64
      %9 = llvm.mul %5, %4 : i64
      %10 = llvm.add %9, %3 : i64
      %11 = llvm.mul %6, %2 : i64
      %12 = llvm.add %11, %3 : i64
      %13 = llvm.mul %7, %1 : i64
      %14 = llvm.add %13, %3 : i64
      %15 = llvm.mul %8, %1 : i64
      %16 = llvm.add %15, %3 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = builtin.unrealized_conversion_cast %17 : i64 to index
      %19 = llvm.add %16, %12 : i64
      %20 = builtin.unrealized_conversion_cast %19 : i64 to index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%21: index):  // 2 preds: ^bb0, ^bb2
      %22 = builtin.unrealized_conversion_cast %21 : index to i64
      %23 = llvm.icmp "slt" %22, %0 : i64
      llvm.cond_br %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %24 = memref.load %arg5[%18, %21] : memref<512x512xf32>
      %25 = memref.load %arg6[%21, %20] : memref<512x512xf32>
      %26 = memref.load %arg7[%18, %20] : memref<512x512xf32>
      %27 = llvm.fmul %24, %25  : f32
      %28 = llvm.fadd %26, %27  : f32
      memref.store %28, %arg7[%18, %20] : memref<512x512xf32>
      %29 = llvm.add %22, %1 : i64
      %30 = builtin.unrealized_conversion_cast %29 : i64 to index
      cf.br ^bb1(%30 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After ReconcileUnrealizedCasts (reconcile-unrealized-casts) //----- //
module attributes {gpu.container_module} {
  llvm.func @matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64, %arg14: !llvm.ptr, %arg15: !llvm.ptr, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: i64) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.insertvalue %arg14, %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.insertvalue %arg15, %1[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.insertvalue %arg16, %2[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.insertvalue %arg17, %3[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.insertvalue %arg19, %4[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.insertvalue %arg18, %5[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg20, %6[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = builtin.unrealized_conversion_cast %7 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %9 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %10 = llvm.insertvalue %arg7, %9[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %arg8, %10[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg9, %11[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.insertvalue %arg10, %12[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.insertvalue %arg12, %13[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg11, %14[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %arg13, %15[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = builtin.unrealized_conversion_cast %16 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %18 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %19 = llvm.insertvalue %arg0, %18[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.insertvalue %arg1, %19[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.insertvalue %arg2, %20[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.insertvalue %arg3, %21[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.insertvalue %arg5, %22[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %24 = llvm.insertvalue %arg4, %23[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %25 = llvm.insertvalue %arg6, %24[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %26 = builtin.unrealized_conversion_cast %25 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %27 = llvm.mlir.constant(16 : index) : i64
    %28 = llvm.mlir.constant(32 : index) : i64
    %29 = llvm.mlir.constant(1 : index) : i64
    %30 = llvm.mlir.constant(512 : index) : i64
    %31 = llvm.mlir.constant(0 : index) : i64
    %32 = builtin.unrealized_conversion_cast %31 : i64 to index
    %33 = builtin.unrealized_conversion_cast %30 : i64 to index
    %34 = builtin.unrealized_conversion_cast %29 : i64 to index
    %35 = builtin.unrealized_conversion_cast %28 : i64 to index
    %36 = builtin.unrealized_conversion_cast %27 : i64 to index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%36, %35, %34) threads in (%35, %36, %34)  args(%35 : index, %32 : index, %36 : index, %34 : index, %33 : index, %26 : memref<512x512xf32>, %17 : memref<512x512xf32>, %8 : memref<512x512xf32>)
    llvm.return
  }
  llvm.func @_mlir_ciface_matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %17 = llvm.extractvalue %16[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.extractvalue %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.extractvalue %16[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.extractvalue %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.extractvalue %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.extractvalue %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.extractvalue %16[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.call @matmul_memref(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15, %17, %18, %19, %20, %21, %22, %23) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> ()
    llvm.return
  }
  gpu.module @matmul_memref_kernel {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %0 = builtin.unrealized_conversion_cast %arg4 : index to i64
      %1 = builtin.unrealized_conversion_cast %arg3 : index to i64
      %2 = builtin.unrealized_conversion_cast %arg2 : index to i64
      %3 = builtin.unrealized_conversion_cast %arg1 : index to i64
      %4 = builtin.unrealized_conversion_cast %arg0 : index to i64
      %block_id_x = gpu.block_id  x
      %5 = builtin.unrealized_conversion_cast %block_id_x : index to i64
      %block_id_y = gpu.block_id  y
      %6 = builtin.unrealized_conversion_cast %block_id_y : index to i64
      %thread_id_x = gpu.thread_id  x
      %7 = builtin.unrealized_conversion_cast %thread_id_x : index to i64
      %thread_id_y = gpu.thread_id  y
      %8 = builtin.unrealized_conversion_cast %thread_id_y : index to i64
      %9 = llvm.mul %5, %4 : i64
      %10 = llvm.add %9, %3 : i64
      %11 = llvm.mul %6, %2 : i64
      %12 = llvm.add %11, %3 : i64
      %13 = llvm.mul %7, %1 : i64
      %14 = llvm.add %13, %3 : i64
      %15 = llvm.mul %8, %1 : i64
      %16 = llvm.add %15, %3 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = builtin.unrealized_conversion_cast %17 : i64 to index
      %19 = llvm.add %16, %12 : i64
      %20 = builtin.unrealized_conversion_cast %19 : i64 to index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%21: index):  // 2 preds: ^bb0, ^bb2
      %22 = builtin.unrealized_conversion_cast %21 : index to i64
      %23 = llvm.icmp "slt" %22, %0 : i64
      llvm.cond_br %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %24 = memref.load %arg5[%18, %21] : memref<512x512xf32>
      %25 = memref.load %arg6[%21, %20] : memref<512x512xf32>
      %26 = memref.load %arg7[%18, %20] : memref<512x512xf32>
      %27 = llvm.fmul %24, %25  : f32
      %28 = llvm.fadd %26, %27  : f32
      memref.store %28, %arg7[%18, %20] : memref<512x512xf32>
      %29 = llvm.add %22, %1 : i64
      %30 = builtin.unrealized_conversion_cast %29 : i64 to index
      cf.br ^bb1(%30 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After (anonymous namespace)::TestTypeConversionDriver (test-legalize-type-conversion) //----- //
module attributes {gpu.container_module} {
  llvm.func @matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64, %arg14: !llvm.ptr, %arg15: !llvm.ptr, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: i64) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.insertvalue %arg14, %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.insertvalue %arg15, %1[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.insertvalue %arg16, %2[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.insertvalue %arg17, %3[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.insertvalue %arg19, %4[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.insertvalue %arg18, %5[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg20, %6[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = builtin.unrealized_conversion_cast %7 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %9 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %10 = llvm.insertvalue %arg7, %9[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %arg8, %10[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg9, %11[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.insertvalue %arg10, %12[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.insertvalue %arg12, %13[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg11, %14[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %arg13, %15[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = builtin.unrealized_conversion_cast %16 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %18 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %19 = llvm.insertvalue %arg0, %18[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.insertvalue %arg1, %19[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.insertvalue %arg2, %20[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.insertvalue %arg3, %21[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.insertvalue %arg5, %22[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %24 = llvm.insertvalue %arg4, %23[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %25 = llvm.insertvalue %arg6, %24[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %26 = builtin.unrealized_conversion_cast %25 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %27 = llvm.mlir.constant(16 : index) : i64
    %28 = llvm.mlir.constant(32 : index) : i64
    %29 = llvm.mlir.constant(1 : index) : i64
    %30 = llvm.mlir.constant(512 : index) : i64
    %31 = llvm.mlir.constant(0 : index) : i64
    %32 = builtin.unrealized_conversion_cast %31 : i64 to index
    %33 = builtin.unrealized_conversion_cast %30 : i64 to index
    %34 = builtin.unrealized_conversion_cast %29 : i64 to index
    %35 = builtin.unrealized_conversion_cast %28 : i64 to index
    %36 = builtin.unrealized_conversion_cast %27 : i64 to index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%36, %35, %34) threads in (%35, %36, %34)  args(%35 : index, %32 : index, %36 : index, %34 : index, %33 : index, %26 : memref<512x512xf32>, %17 : memref<512x512xf32>, %8 : memref<512x512xf32>)
    llvm.return
  }
  llvm.func @_mlir_ciface_matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %17 = llvm.extractvalue %16[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.extractvalue %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.extractvalue %16[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.extractvalue %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.extractvalue %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.extractvalue %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.extractvalue %16[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.call @matmul_memref(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15, %17, %18, %19, %20, %21, %22, %23) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> ()
    llvm.return
  }
  gpu.module @matmul_memref_kernel {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %0 = builtin.unrealized_conversion_cast %arg4 : index to i64
      %1 = builtin.unrealized_conversion_cast %arg3 : index to i64
      %2 = builtin.unrealized_conversion_cast %arg2 : index to i64
      %3 = builtin.unrealized_conversion_cast %arg1 : index to i64
      %4 = builtin.unrealized_conversion_cast %arg0 : index to i64
      %block_id_x = gpu.block_id  x
      %5 = builtin.unrealized_conversion_cast %block_id_x : index to i64
      %block_id_y = gpu.block_id  y
      %6 = builtin.unrealized_conversion_cast %block_id_y : index to i64
      %thread_id_x = gpu.thread_id  x
      %7 = builtin.unrealized_conversion_cast %thread_id_x : index to i64
      %thread_id_y = gpu.thread_id  y
      %8 = builtin.unrealized_conversion_cast %thread_id_y : index to i64
      %9 = llvm.mul %5, %4 : i64
      %10 = llvm.add %9, %3 : i64
      %11 = llvm.mul %6, %2 : i64
      %12 = llvm.add %11, %3 : i64
      %13 = llvm.mul %7, %1 : i64
      %14 = llvm.add %13, %3 : i64
      %15 = llvm.mul %8, %1 : i64
      %16 = llvm.add %15, %3 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = builtin.unrealized_conversion_cast %17 : i64 to index
      %19 = llvm.add %16, %12 : i64
      %20 = builtin.unrealized_conversion_cast %19 : i64 to index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%21: index):  // 2 preds: ^bb0, ^bb2
      %22 = builtin.unrealized_conversion_cast %21 : index to i64
      %23 = llvm.icmp "slt" %22, %0 : i64
      llvm.cond_br %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %24 = memref.load %arg5[%18, %21] : memref<512x512xf32>
      %25 = memref.load %arg6[%21, %20] : memref<512x512xf32>
      %26 = memref.load %arg7[%18, %20] : memref<512x512xf32>
      %27 = llvm.fmul %24, %25  : f32
      %28 = llvm.fadd %26, %27  : f32
      memref.store %28, %arg7[%18, %20] : memref<512x512xf32>
      %29 = llvm.add %22, %1 : i64
      %30 = builtin.unrealized_conversion_cast %29 : i64 to index
      cf.br ^bb1(%30 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module attributes {gpu.container_module} {
  llvm.func @matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64, %arg14: !llvm.ptr, %arg15: !llvm.ptr, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: i64) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(512 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i64
    %3 = llvm.mlir.constant(32 : index) : i64
    %4 = llvm.mlir.constant(16 : index) : i64
    %5 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %6 = llvm.insertvalue %arg14, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg15, %6[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.insertvalue %arg16, %7[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %9 = llvm.insertvalue %arg17, %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.insertvalue %arg19, %9[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %arg18, %10[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg20, %11[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = builtin.unrealized_conversion_cast %12 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %14 = llvm.insertvalue %arg7, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg8, %14[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %arg9, %15[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %arg10, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %arg12, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %arg11, %18[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.insertvalue %arg13, %19[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = builtin.unrealized_conversion_cast %20 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %22 = llvm.insertvalue %arg0, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.insertvalue %arg1, %22[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %24 = llvm.insertvalue %arg2, %23[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %25 = llvm.insertvalue %arg3, %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %26 = llvm.insertvalue %arg5, %25[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %27 = llvm.insertvalue %arg4, %26[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %28 = llvm.insertvalue %arg6, %27[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %29 = builtin.unrealized_conversion_cast %28 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %30 = builtin.unrealized_conversion_cast %0 : i64 to index
    %31 = builtin.unrealized_conversion_cast %1 : i64 to index
    %32 = builtin.unrealized_conversion_cast %2 : i64 to index
    %33 = builtin.unrealized_conversion_cast %3 : i64 to index
    %34 = builtin.unrealized_conversion_cast %4 : i64 to index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%34, %33, %32) threads in (%33, %34, %32)  args(%33 : index, %30 : index, %34 : index, %32 : index, %31 : index, %29 : memref<512x512xf32>, %21 : memref<512x512xf32>, %13 : memref<512x512xf32>)
    llvm.return
  }
  llvm.func @_mlir_ciface_matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %17 = llvm.extractvalue %16[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.extractvalue %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.extractvalue %16[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.extractvalue %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.extractvalue %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.extractvalue %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.extractvalue %16[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.call @matmul_memref(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15, %17, %18, %19, %20, %21, %22, %23) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> ()
    llvm.return
  }
  gpu.module @matmul_memref_kernel {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %0 = builtin.unrealized_conversion_cast %arg4 : index to i64
      %1 = builtin.unrealized_conversion_cast %arg3 : index to i64
      %2 = builtin.unrealized_conversion_cast %arg2 : index to i64
      %3 = builtin.unrealized_conversion_cast %arg1 : index to i64
      %4 = builtin.unrealized_conversion_cast %arg0 : index to i64
      %block_id_x = gpu.block_id  x
      %5 = builtin.unrealized_conversion_cast %block_id_x : index to i64
      %block_id_y = gpu.block_id  y
      %6 = builtin.unrealized_conversion_cast %block_id_y : index to i64
      %thread_id_x = gpu.thread_id  x
      %7 = builtin.unrealized_conversion_cast %thread_id_x : index to i64
      %thread_id_y = gpu.thread_id  y
      %8 = builtin.unrealized_conversion_cast %thread_id_y : index to i64
      %9 = llvm.mul %5, %4 : i64
      %10 = llvm.add %9, %3 : i64
      %11 = llvm.mul %6, %2 : i64
      %12 = llvm.add %11, %3 : i64
      %13 = llvm.mul %7, %1 : i64
      %14 = llvm.add %13, %3 : i64
      %15 = llvm.mul %8, %1 : i64
      %16 = llvm.add %15, %3 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = builtin.unrealized_conversion_cast %17 : i64 to index
      %19 = llvm.add %16, %12 : i64
      %20 = builtin.unrealized_conversion_cast %19 : i64 to index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%21: index):  // 2 preds: ^bb0, ^bb2
      %22 = builtin.unrealized_conversion_cast %21 : index to i64
      %23 = llvm.icmp "slt" %22, %0 : i64
      llvm.cond_br %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %24 = memref.load %arg5[%18, %21] : memref<512x512xf32>
      %25 = memref.load %arg6[%21, %20] : memref<512x512xf32>
      %26 = memref.load %arg7[%18, %20] : memref<512x512xf32>
      %27 = llvm.fmul %24, %25  : f32
      %28 = llvm.fadd %26, %27  : f32
      memref.store %28, %arg7[%18, %20] : memref<512x512xf32>
      %29 = llvm.add %22, %1 : i64
      %30 = builtin.unrealized_conversion_cast %29 : i64 to index
      cf.br ^bb1(%30 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After ConvertNVGPUToNVVMPass (convert-nvgpu-to-nvvm) //----- //
module attributes {gpu.container_module} {
  llvm.func @matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64, %arg14: !llvm.ptr, %arg15: !llvm.ptr, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: i64) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(512 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i64
    %3 = llvm.mlir.constant(32 : index) : i64
    %4 = llvm.mlir.constant(16 : index) : i64
    %5 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %6 = llvm.insertvalue %arg14, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg15, %6[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.insertvalue %arg16, %7[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %9 = llvm.insertvalue %arg17, %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.insertvalue %arg19, %9[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %arg18, %10[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg20, %11[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = builtin.unrealized_conversion_cast %12 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %14 = llvm.insertvalue %arg7, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg8, %14[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %arg9, %15[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %arg10, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %arg12, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %arg11, %18[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.insertvalue %arg13, %19[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = builtin.unrealized_conversion_cast %20 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %22 = llvm.insertvalue %arg0, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.insertvalue %arg1, %22[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %24 = llvm.insertvalue %arg2, %23[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %25 = llvm.insertvalue %arg3, %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %26 = llvm.insertvalue %arg5, %25[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %27 = llvm.insertvalue %arg4, %26[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %28 = llvm.insertvalue %arg6, %27[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %29 = builtin.unrealized_conversion_cast %28 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %30 = builtin.unrealized_conversion_cast %0 : i64 to index
    %31 = builtin.unrealized_conversion_cast %1 : i64 to index
    %32 = builtin.unrealized_conversion_cast %2 : i64 to index
    %33 = builtin.unrealized_conversion_cast %3 : i64 to index
    %34 = builtin.unrealized_conversion_cast %4 : i64 to index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%34, %33, %32) threads in (%33, %34, %32)  args(%33 : index, %30 : index, %34 : index, %32 : index, %31 : index, %29 : memref<512x512xf32>, %21 : memref<512x512xf32>, %13 : memref<512x512xf32>)
    llvm.return
  }
  llvm.func @_mlir_ciface_matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %17 = llvm.extractvalue %16[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.extractvalue %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.extractvalue %16[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.extractvalue %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.extractvalue %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.extractvalue %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.extractvalue %16[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.call @matmul_memref(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15, %17, %18, %19, %20, %21, %22, %23) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> ()
    llvm.return
  }
  gpu.module @matmul_memref_kernel {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %0 = builtin.unrealized_conversion_cast %arg4 : index to i64
      %1 = builtin.unrealized_conversion_cast %arg3 : index to i64
      %2 = builtin.unrealized_conversion_cast %arg2 : index to i64
      %3 = builtin.unrealized_conversion_cast %arg1 : index to i64
      %4 = builtin.unrealized_conversion_cast %arg0 : index to i64
      %block_id_x = gpu.block_id  x
      %5 = builtin.unrealized_conversion_cast %block_id_x : index to i64
      %block_id_y = gpu.block_id  y
      %6 = builtin.unrealized_conversion_cast %block_id_y : index to i64
      %thread_id_x = gpu.thread_id  x
      %7 = builtin.unrealized_conversion_cast %thread_id_x : index to i64
      %thread_id_y = gpu.thread_id  y
      %8 = builtin.unrealized_conversion_cast %thread_id_y : index to i64
      %9 = llvm.mul %5, %4 : i64
      %10 = llvm.add %9, %3 : i64
      %11 = llvm.mul %6, %2 : i64
      %12 = llvm.add %11, %3 : i64
      %13 = llvm.mul %7, %1 : i64
      %14 = llvm.add %13, %3 : i64
      %15 = llvm.mul %8, %1 : i64
      %16 = llvm.add %15, %3 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = builtin.unrealized_conversion_cast %17 : i64 to index
      %19 = llvm.add %16, %12 : i64
      %20 = builtin.unrealized_conversion_cast %19 : i64 to index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%21: index):  // 2 preds: ^bb0, ^bb2
      %22 = builtin.unrealized_conversion_cast %21 : index to i64
      %23 = llvm.icmp "slt" %22, %0 : i64
      llvm.cond_br %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %24 = memref.load %arg5[%18, %21] : memref<512x512xf32>
      %25 = memref.load %arg6[%21, %20] : memref<512x512xf32>
      %26 = memref.load %arg7[%18, %20] : memref<512x512xf32>
      %27 = llvm.fmul %24, %25  : f32
      %28 = llvm.fadd %26, %27  : f32
      memref.store %28, %arg7[%18, %20] : memref<512x512xf32>
      %29 = llvm.add %22, %1 : i64
      %30 = builtin.unrealized_conversion_cast %29 : i64 to index
      cf.br ^bb1(%30 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After GpuKernelOutlining (gpu-kernel-outlining) //----- //
module attributes {gpu.container_module} {
  llvm.func @matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64, %arg14: !llvm.ptr, %arg15: !llvm.ptr, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: i64) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(512 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i64
    %3 = llvm.mlir.constant(32 : index) : i64
    %4 = llvm.mlir.constant(16 : index) : i64
    %5 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %6 = llvm.insertvalue %arg14, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg15, %6[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.insertvalue %arg16, %7[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %9 = llvm.insertvalue %arg17, %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.insertvalue %arg19, %9[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %arg18, %10[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg20, %11[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = builtin.unrealized_conversion_cast %12 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %14 = llvm.insertvalue %arg7, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg8, %14[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %arg9, %15[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %arg10, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %arg12, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %arg11, %18[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.insertvalue %arg13, %19[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = builtin.unrealized_conversion_cast %20 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %22 = llvm.insertvalue %arg0, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.insertvalue %arg1, %22[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %24 = llvm.insertvalue %arg2, %23[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %25 = llvm.insertvalue %arg3, %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %26 = llvm.insertvalue %arg5, %25[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %27 = llvm.insertvalue %arg4, %26[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %28 = llvm.insertvalue %arg6, %27[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %29 = builtin.unrealized_conversion_cast %28 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %30 = builtin.unrealized_conversion_cast %0 : i64 to index
    %31 = builtin.unrealized_conversion_cast %1 : i64 to index
    %32 = builtin.unrealized_conversion_cast %2 : i64 to index
    %33 = builtin.unrealized_conversion_cast %3 : i64 to index
    %34 = builtin.unrealized_conversion_cast %4 : i64 to index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%34, %33, %32) threads in (%33, %34, %32)  args(%33 : index, %30 : index, %34 : index, %32 : index, %31 : index, %29 : memref<512x512xf32>, %21 : memref<512x512xf32>, %13 : memref<512x512xf32>)
    llvm.return
  }
  llvm.func @_mlir_ciface_matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %17 = llvm.extractvalue %16[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.extractvalue %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.extractvalue %16[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.extractvalue %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.extractvalue %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.extractvalue %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.extractvalue %16[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.call @matmul_memref(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15, %17, %18, %19, %20, %21, %22, %23) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> ()
    llvm.return
  }
  gpu.module @matmul_memref_kernel {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %0 = builtin.unrealized_conversion_cast %arg4 : index to i64
      %1 = builtin.unrealized_conversion_cast %arg3 : index to i64
      %2 = builtin.unrealized_conversion_cast %arg2 : index to i64
      %3 = builtin.unrealized_conversion_cast %arg1 : index to i64
      %4 = builtin.unrealized_conversion_cast %arg0 : index to i64
      %block_id_x = gpu.block_id  x
      %5 = builtin.unrealized_conversion_cast %block_id_x : index to i64
      %block_id_y = gpu.block_id  y
      %6 = builtin.unrealized_conversion_cast %block_id_y : index to i64
      %thread_id_x = gpu.thread_id  x
      %7 = builtin.unrealized_conversion_cast %thread_id_x : index to i64
      %thread_id_y = gpu.thread_id  y
      %8 = builtin.unrealized_conversion_cast %thread_id_y : index to i64
      %9 = llvm.mul %5, %4 : i64
      %10 = llvm.add %9, %3 : i64
      %11 = llvm.mul %6, %2 : i64
      %12 = llvm.add %11, %3 : i64
      %13 = llvm.mul %7, %1 : i64
      %14 = llvm.add %13, %3 : i64
      %15 = llvm.mul %8, %1 : i64
      %16 = llvm.add %15, %3 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = builtin.unrealized_conversion_cast %17 : i64 to index
      %19 = llvm.add %16, %12 : i64
      %20 = builtin.unrealized_conversion_cast %19 : i64 to index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%21: index):  // 2 preds: ^bb0, ^bb2
      %22 = builtin.unrealized_conversion_cast %21 : index to i64
      %23 = llvm.icmp "slt" %22, %0 : i64
      llvm.cond_br %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %24 = memref.load %arg5[%18, %21] : memref<512x512xf32>
      %25 = memref.load %arg6[%21, %20] : memref<512x512xf32>
      %26 = memref.load %arg7[%18, %20] : memref<512x512xf32>
      %27 = llvm.fmul %24, %25  : f32
      %28 = llvm.fadd %26, %27  : f32
      memref.store %28, %arg7[%18, %20] : memref<512x512xf32>
      %29 = llvm.add %22, %1 : i64
      %30 = builtin.unrealized_conversion_cast %29 : i64 to index
      cf.br ^bb1(%30 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After ConvertVectorToSCF (convert-vector-to-scf) //----- //
module attributes {gpu.container_module} {
  llvm.func @matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64, %arg14: !llvm.ptr, %arg15: !llvm.ptr, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: i64) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(512 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i64
    %3 = llvm.mlir.constant(32 : index) : i64
    %4 = llvm.mlir.constant(16 : index) : i64
    %5 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %6 = llvm.insertvalue %arg14, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg15, %6[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.insertvalue %arg16, %7[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %9 = llvm.insertvalue %arg17, %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.insertvalue %arg19, %9[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %arg18, %10[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg20, %11[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = builtin.unrealized_conversion_cast %12 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %14 = llvm.insertvalue %arg7, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg8, %14[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %arg9, %15[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %arg10, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %arg12, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %arg11, %18[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.insertvalue %arg13, %19[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = builtin.unrealized_conversion_cast %20 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %22 = llvm.insertvalue %arg0, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.insertvalue %arg1, %22[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %24 = llvm.insertvalue %arg2, %23[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %25 = llvm.insertvalue %arg3, %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %26 = llvm.insertvalue %arg5, %25[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %27 = llvm.insertvalue %arg4, %26[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %28 = llvm.insertvalue %arg6, %27[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %29 = builtin.unrealized_conversion_cast %28 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %30 = builtin.unrealized_conversion_cast %0 : i64 to index
    %31 = builtin.unrealized_conversion_cast %1 : i64 to index
    %32 = builtin.unrealized_conversion_cast %2 : i64 to index
    %33 = builtin.unrealized_conversion_cast %3 : i64 to index
    %34 = builtin.unrealized_conversion_cast %4 : i64 to index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%34, %33, %32) threads in (%33, %34, %32)  args(%33 : index, %30 : index, %34 : index, %32 : index, %31 : index, %29 : memref<512x512xf32>, %21 : memref<512x512xf32>, %13 : memref<512x512xf32>)
    llvm.return
  }
  llvm.func @_mlir_ciface_matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %17 = llvm.extractvalue %16[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.extractvalue %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.extractvalue %16[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.extractvalue %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.extractvalue %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.extractvalue %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.extractvalue %16[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.call @matmul_memref(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15, %17, %18, %19, %20, %21, %22, %23) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> ()
    llvm.return
  }
  gpu.module @matmul_memref_kernel {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %0 = builtin.unrealized_conversion_cast %arg4 : index to i64
      %1 = builtin.unrealized_conversion_cast %arg3 : index to i64
      %2 = builtin.unrealized_conversion_cast %arg2 : index to i64
      %3 = builtin.unrealized_conversion_cast %arg1 : index to i64
      %4 = builtin.unrealized_conversion_cast %arg0 : index to i64
      %block_id_x = gpu.block_id  x
      %5 = builtin.unrealized_conversion_cast %block_id_x : index to i64
      %block_id_y = gpu.block_id  y
      %6 = builtin.unrealized_conversion_cast %block_id_y : index to i64
      %thread_id_x = gpu.thread_id  x
      %7 = builtin.unrealized_conversion_cast %thread_id_x : index to i64
      %thread_id_y = gpu.thread_id  y
      %8 = builtin.unrealized_conversion_cast %thread_id_y : index to i64
      %9 = llvm.mul %5, %4 : i64
      %10 = llvm.add %9, %3 : i64
      %11 = llvm.mul %6, %2 : i64
      %12 = llvm.add %11, %3 : i64
      %13 = llvm.mul %7, %1 : i64
      %14 = llvm.add %13, %3 : i64
      %15 = llvm.mul %8, %1 : i64
      %16 = llvm.add %15, %3 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = builtin.unrealized_conversion_cast %17 : i64 to index
      %19 = llvm.add %16, %12 : i64
      %20 = builtin.unrealized_conversion_cast %19 : i64 to index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%21: index):  // 2 preds: ^bb0, ^bb2
      %22 = builtin.unrealized_conversion_cast %21 : index to i64
      %23 = llvm.icmp "slt" %22, %0 : i64
      llvm.cond_br %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %24 = memref.load %arg5[%18, %21] : memref<512x512xf32>
      %25 = memref.load %arg6[%21, %20] : memref<512x512xf32>
      %26 = memref.load %arg7[%18, %20] : memref<512x512xf32>
      %27 = llvm.fmul %24, %25  : f32
      %28 = llvm.fadd %26, %27  : f32
      memref.store %28, %arg7[%18, %20] : memref<512x512xf32>
      %29 = llvm.add %22, %1 : i64
      %30 = builtin.unrealized_conversion_cast %29 : i64 to index
      cf.br ^bb1(%30 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
module attributes {gpu.container_module} {
  llvm.func @matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64, %arg14: !llvm.ptr, %arg15: !llvm.ptr, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: i64) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(512 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i64
    %3 = llvm.mlir.constant(32 : index) : i64
    %4 = llvm.mlir.constant(16 : index) : i64
    %5 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %6 = llvm.insertvalue %arg14, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg15, %6[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.insertvalue %arg16, %7[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %9 = llvm.insertvalue %arg17, %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.insertvalue %arg19, %9[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %arg18, %10[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg20, %11[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = builtin.unrealized_conversion_cast %12 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %14 = llvm.insertvalue %arg7, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg8, %14[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %arg9, %15[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %arg10, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %arg12, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %arg11, %18[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.insertvalue %arg13, %19[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = builtin.unrealized_conversion_cast %20 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %22 = llvm.insertvalue %arg0, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.insertvalue %arg1, %22[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %24 = llvm.insertvalue %arg2, %23[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %25 = llvm.insertvalue %arg3, %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %26 = llvm.insertvalue %arg5, %25[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %27 = llvm.insertvalue %arg4, %26[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %28 = llvm.insertvalue %arg6, %27[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %29 = builtin.unrealized_conversion_cast %28 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %30 = builtin.unrealized_conversion_cast %0 : i64 to index
    %31 = builtin.unrealized_conversion_cast %1 : i64 to index
    %32 = builtin.unrealized_conversion_cast %2 : i64 to index
    %33 = builtin.unrealized_conversion_cast %3 : i64 to index
    %34 = builtin.unrealized_conversion_cast %4 : i64 to index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%34, %33, %32) threads in (%33, %34, %32)  args(%33 : index, %30 : index, %34 : index, %32 : index, %31 : index, %29 : memref<512x512xf32>, %21 : memref<512x512xf32>, %13 : memref<512x512xf32>)
    llvm.return
  }
  llvm.func @_mlir_ciface_matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %17 = llvm.extractvalue %16[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.extractvalue %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.extractvalue %16[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.extractvalue %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.extractvalue %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.extractvalue %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.extractvalue %16[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.call @matmul_memref(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15, %17, %18, %19, %20, %21, %22, %23) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> ()
    llvm.return
  }
  gpu.module @matmul_memref_kernel {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %0 = builtin.unrealized_conversion_cast %arg4 : index to i64
      %1 = builtin.unrealized_conversion_cast %arg3 : index to i64
      %2 = builtin.unrealized_conversion_cast %arg2 : index to i64
      %3 = builtin.unrealized_conversion_cast %arg1 : index to i64
      %4 = builtin.unrealized_conversion_cast %arg0 : index to i64
      %block_id_x = gpu.block_id  x
      %5 = builtin.unrealized_conversion_cast %block_id_x : index to i64
      %block_id_y = gpu.block_id  y
      %6 = builtin.unrealized_conversion_cast %block_id_y : index to i64
      %thread_id_x = gpu.thread_id  x
      %7 = builtin.unrealized_conversion_cast %thread_id_x : index to i64
      %thread_id_y = gpu.thread_id  y
      %8 = builtin.unrealized_conversion_cast %thread_id_y : index to i64
      %9 = llvm.mul %5, %4 : i64
      %10 = llvm.add %9, %3 : i64
      %11 = llvm.mul %6, %2 : i64
      %12 = llvm.add %11, %3 : i64
      %13 = llvm.mul %7, %1 : i64
      %14 = llvm.add %13, %3 : i64
      %15 = llvm.mul %8, %1 : i64
      %16 = llvm.add %15, %3 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = builtin.unrealized_conversion_cast %17 : i64 to index
      %19 = llvm.add %16, %12 : i64
      %20 = builtin.unrealized_conversion_cast %19 : i64 to index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%21: index):  // 2 preds: ^bb0, ^bb2
      %22 = builtin.unrealized_conversion_cast %21 : index to i64
      %23 = llvm.icmp "slt" %22, %0 : i64
      llvm.cond_br %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %24 = memref.load %arg5[%18, %21] : memref<512x512xf32>
      %25 = memref.load %arg6[%21, %20] : memref<512x512xf32>
      %26 = memref.load %arg7[%18, %20] : memref<512x512xf32>
      %27 = llvm.fmul %24, %25  : f32
      %28 = llvm.fadd %26, %27  : f32
      memref.store %28, %arg7[%18, %20] : memref<512x512xf32>
      %29 = llvm.add %22, %1 : i64
      %30 = builtin.unrealized_conversion_cast %29 : i64 to index
      cf.br ^bb1(%30 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After ConvertNVVMToLLVMPass (convert-nvvm-to-llvm) //----- //
module attributes {gpu.container_module} {
  llvm.func @matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64, %arg14: !llvm.ptr, %arg15: !llvm.ptr, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: i64) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(512 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i64
    %3 = llvm.mlir.constant(32 : index) : i64
    %4 = llvm.mlir.constant(16 : index) : i64
    %5 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %6 = llvm.insertvalue %arg14, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg15, %6[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.insertvalue %arg16, %7[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %9 = llvm.insertvalue %arg17, %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.insertvalue %arg19, %9[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %arg18, %10[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg20, %11[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = builtin.unrealized_conversion_cast %12 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %14 = llvm.insertvalue %arg7, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg8, %14[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %arg9, %15[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %arg10, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %arg12, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %arg11, %18[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.insertvalue %arg13, %19[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = builtin.unrealized_conversion_cast %20 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %22 = llvm.insertvalue %arg0, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.insertvalue %arg1, %22[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %24 = llvm.insertvalue %arg2, %23[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %25 = llvm.insertvalue %arg3, %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %26 = llvm.insertvalue %arg5, %25[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %27 = llvm.insertvalue %arg4, %26[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %28 = llvm.insertvalue %arg6, %27[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %29 = builtin.unrealized_conversion_cast %28 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %30 = builtin.unrealized_conversion_cast %0 : i64 to index
    %31 = builtin.unrealized_conversion_cast %1 : i64 to index
    %32 = builtin.unrealized_conversion_cast %2 : i64 to index
    %33 = builtin.unrealized_conversion_cast %3 : i64 to index
    %34 = builtin.unrealized_conversion_cast %4 : i64 to index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%34, %33, %32) threads in (%33, %34, %32)  args(%33 : index, %30 : index, %34 : index, %32 : index, %31 : index, %29 : memref<512x512xf32>, %21 : memref<512x512xf32>, %13 : memref<512x512xf32>)
    llvm.return
  }
  llvm.func @_mlir_ciface_matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %17 = llvm.extractvalue %16[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.extractvalue %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.extractvalue %16[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.extractvalue %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.extractvalue %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.extractvalue %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.extractvalue %16[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.call @matmul_memref(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15, %17, %18, %19, %20, %21, %22, %23) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> ()
    llvm.return
  }
  gpu.module @matmul_memref_kernel {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %0 = builtin.unrealized_conversion_cast %arg4 : index to i64
      %1 = builtin.unrealized_conversion_cast %arg3 : index to i64
      %2 = builtin.unrealized_conversion_cast %arg2 : index to i64
      %3 = builtin.unrealized_conversion_cast %arg1 : index to i64
      %4 = builtin.unrealized_conversion_cast %arg0 : index to i64
      %block_id_x = gpu.block_id  x
      %5 = builtin.unrealized_conversion_cast %block_id_x : index to i64
      %block_id_y = gpu.block_id  y
      %6 = builtin.unrealized_conversion_cast %block_id_y : index to i64
      %thread_id_x = gpu.thread_id  x
      %7 = builtin.unrealized_conversion_cast %thread_id_x : index to i64
      %thread_id_y = gpu.thread_id  y
      %8 = builtin.unrealized_conversion_cast %thread_id_y : index to i64
      %9 = llvm.mul %5, %4 : i64
      %10 = llvm.add %9, %3 : i64
      %11 = llvm.mul %6, %2 : i64
      %12 = llvm.add %11, %3 : i64
      %13 = llvm.mul %7, %1 : i64
      %14 = llvm.add %13, %3 : i64
      %15 = llvm.mul %8, %1 : i64
      %16 = llvm.add %15, %3 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = builtin.unrealized_conversion_cast %17 : i64 to index
      %19 = llvm.add %16, %12 : i64
      %20 = builtin.unrealized_conversion_cast %19 : i64 to index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%21: index):  // 2 preds: ^bb0, ^bb2
      %22 = builtin.unrealized_conversion_cast %21 : index to i64
      %23 = llvm.icmp "slt" %22, %0 : i64
      llvm.cond_br %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %24 = memref.load %arg5[%18, %21] : memref<512x512xf32>
      %25 = memref.load %arg6[%21, %20] : memref<512x512xf32>
      %26 = memref.load %arg7[%18, %20] : memref<512x512xf32>
      %27 = llvm.fmul %24, %25  : f32
      %28 = llvm.fadd %26, %27  : f32
      memref.store %28, %arg7[%18, %20] : memref<512x512xf32>
      %29 = llvm.add %22, %1 : i64
      %30 = builtin.unrealized_conversion_cast %29 : i64 to index
      cf.br ^bb1(%30 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After ConvertFuncToLLVMPass (convert-func-to-llvm) //----- //
module attributes {gpu.container_module} {
  llvm.func @matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64, %arg14: !llvm.ptr, %arg15: !llvm.ptr, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: i64) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(512 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i64
    %3 = llvm.mlir.constant(32 : index) : i64
    %4 = llvm.mlir.constant(16 : index) : i64
    %5 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %6 = llvm.insertvalue %arg14, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg15, %6[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.insertvalue %arg16, %7[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %9 = llvm.insertvalue %arg17, %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.insertvalue %arg19, %9[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %arg18, %10[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg20, %11[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = builtin.unrealized_conversion_cast %12 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %14 = llvm.insertvalue %arg7, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg8, %14[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %arg9, %15[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %arg10, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %arg12, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %arg11, %18[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.insertvalue %arg13, %19[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = builtin.unrealized_conversion_cast %20 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %22 = llvm.insertvalue %arg0, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.insertvalue %arg1, %22[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %24 = llvm.insertvalue %arg2, %23[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %25 = llvm.insertvalue %arg3, %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %26 = llvm.insertvalue %arg5, %25[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %27 = llvm.insertvalue %arg4, %26[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %28 = llvm.insertvalue %arg6, %27[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %29 = builtin.unrealized_conversion_cast %28 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %30 = builtin.unrealized_conversion_cast %0 : i64 to index
    %31 = builtin.unrealized_conversion_cast %1 : i64 to index
    %32 = builtin.unrealized_conversion_cast %2 : i64 to index
    %33 = builtin.unrealized_conversion_cast %3 : i64 to index
    %34 = builtin.unrealized_conversion_cast %4 : i64 to index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%34, %33, %32) threads in (%33, %34, %32)  args(%33 : index, %30 : index, %34 : index, %32 : index, %31 : index, %29 : memref<512x512xf32>, %21 : memref<512x512xf32>, %13 : memref<512x512xf32>)
    llvm.return
  }
  llvm.func @_mlir_ciface_matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %17 = llvm.extractvalue %16[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.extractvalue %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.extractvalue %16[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.extractvalue %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.extractvalue %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.extractvalue %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.extractvalue %16[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.call @matmul_memref(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15, %17, %18, %19, %20, %21, %22, %23) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> ()
    llvm.return
  }
  gpu.module @matmul_memref_kernel {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %0 = builtin.unrealized_conversion_cast %arg4 : index to i64
      %1 = builtin.unrealized_conversion_cast %arg3 : index to i64
      %2 = builtin.unrealized_conversion_cast %arg2 : index to i64
      %3 = builtin.unrealized_conversion_cast %arg1 : index to i64
      %4 = builtin.unrealized_conversion_cast %arg0 : index to i64
      %block_id_x = gpu.block_id  x
      %5 = builtin.unrealized_conversion_cast %block_id_x : index to i64
      %block_id_y = gpu.block_id  y
      %6 = builtin.unrealized_conversion_cast %block_id_y : index to i64
      %thread_id_x = gpu.thread_id  x
      %7 = builtin.unrealized_conversion_cast %thread_id_x : index to i64
      %thread_id_y = gpu.thread_id  y
      %8 = builtin.unrealized_conversion_cast %thread_id_y : index to i64
      %9 = llvm.mul %5, %4 : i64
      %10 = llvm.add %9, %3 : i64
      %11 = llvm.mul %6, %2 : i64
      %12 = llvm.add %11, %3 : i64
      %13 = llvm.mul %7, %1 : i64
      %14 = llvm.add %13, %3 : i64
      %15 = llvm.mul %8, %1 : i64
      %16 = llvm.add %15, %3 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = builtin.unrealized_conversion_cast %17 : i64 to index
      %19 = llvm.add %16, %12 : i64
      %20 = builtin.unrealized_conversion_cast %19 : i64 to index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%21: index):  // 2 preds: ^bb0, ^bb2
      %22 = builtin.unrealized_conversion_cast %21 : index to i64
      %23 = llvm.icmp "slt" %22, %0 : i64
      llvm.cond_br %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %24 = memref.load %arg5[%18, %21] : memref<512x512xf32>
      %25 = memref.load %arg6[%21, %20] : memref<512x512xf32>
      %26 = memref.load %arg7[%18, %20] : memref<512x512xf32>
      %27 = llvm.fmul %24, %25  : f32
      %28 = llvm.fadd %26, %27  : f32
      memref.store %28, %arg7[%18, %20] : memref<512x512xf32>
      %29 = llvm.add %22, %1 : i64
      %30 = builtin.unrealized_conversion_cast %29 : i64 to index
      cf.br ^bb1(%30 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After ExpandStridedMetadata (expand-strided-metadata) //----- //
module attributes {gpu.container_module} {
  llvm.func @matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64, %arg14: !llvm.ptr, %arg15: !llvm.ptr, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: i64) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(512 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i64
    %3 = llvm.mlir.constant(32 : index) : i64
    %4 = llvm.mlir.constant(16 : index) : i64
    %5 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %6 = llvm.insertvalue %arg14, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg15, %6[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.insertvalue %arg16, %7[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %9 = llvm.insertvalue %arg17, %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.insertvalue %arg19, %9[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %arg18, %10[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg20, %11[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = builtin.unrealized_conversion_cast %12 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %14 = llvm.insertvalue %arg7, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg8, %14[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %arg9, %15[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %arg10, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %arg12, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %arg11, %18[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.insertvalue %arg13, %19[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = builtin.unrealized_conversion_cast %20 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %22 = llvm.insertvalue %arg0, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.insertvalue %arg1, %22[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %24 = llvm.insertvalue %arg2, %23[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %25 = llvm.insertvalue %arg3, %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %26 = llvm.insertvalue %arg5, %25[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %27 = llvm.insertvalue %arg4, %26[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %28 = llvm.insertvalue %arg6, %27[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %29 = builtin.unrealized_conversion_cast %28 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %30 = builtin.unrealized_conversion_cast %0 : i64 to index
    %31 = builtin.unrealized_conversion_cast %1 : i64 to index
    %32 = builtin.unrealized_conversion_cast %2 : i64 to index
    %33 = builtin.unrealized_conversion_cast %3 : i64 to index
    %34 = builtin.unrealized_conversion_cast %4 : i64 to index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%34, %33, %32) threads in (%33, %34, %32)  args(%33 : index, %30 : index, %34 : index, %32 : index, %31 : index, %29 : memref<512x512xf32>, %21 : memref<512x512xf32>, %13 : memref<512x512xf32>)
    llvm.return
  }
  llvm.func @_mlir_ciface_matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %17 = llvm.extractvalue %16[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.extractvalue %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.extractvalue %16[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.extractvalue %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.extractvalue %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.extractvalue %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.extractvalue %16[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.call @matmul_memref(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15, %17, %18, %19, %20, %21, %22, %23) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> ()
    llvm.return
  }
  gpu.module @matmul_memref_kernel {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %0 = builtin.unrealized_conversion_cast %arg4 : index to i64
      %1 = builtin.unrealized_conversion_cast %arg3 : index to i64
      %2 = builtin.unrealized_conversion_cast %arg2 : index to i64
      %3 = builtin.unrealized_conversion_cast %arg1 : index to i64
      %4 = builtin.unrealized_conversion_cast %arg0 : index to i64
      %block_id_x = gpu.block_id  x
      %5 = builtin.unrealized_conversion_cast %block_id_x : index to i64
      %block_id_y = gpu.block_id  y
      %6 = builtin.unrealized_conversion_cast %block_id_y : index to i64
      %thread_id_x = gpu.thread_id  x
      %7 = builtin.unrealized_conversion_cast %thread_id_x : index to i64
      %thread_id_y = gpu.thread_id  y
      %8 = builtin.unrealized_conversion_cast %thread_id_y : index to i64
      %9 = llvm.mul %5, %4 : i64
      %10 = llvm.add %9, %3 : i64
      %11 = llvm.mul %6, %2 : i64
      %12 = llvm.add %11, %3 : i64
      %13 = llvm.mul %7, %1 : i64
      %14 = llvm.add %13, %3 : i64
      %15 = llvm.mul %8, %1 : i64
      %16 = llvm.add %15, %3 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = builtin.unrealized_conversion_cast %17 : i64 to index
      %19 = llvm.add %16, %12 : i64
      %20 = builtin.unrealized_conversion_cast %19 : i64 to index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%21: index):  // 2 preds: ^bb0, ^bb2
      %22 = builtin.unrealized_conversion_cast %21 : index to i64
      %23 = llvm.icmp "slt" %22, %0 : i64
      llvm.cond_br %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %24 = memref.load %arg5[%18, %21] : memref<512x512xf32>
      %25 = memref.load %arg6[%21, %20] : memref<512x512xf32>
      %26 = memref.load %arg7[%18, %20] : memref<512x512xf32>
      %27 = llvm.fmul %24, %25  : f32
      %28 = llvm.fadd %26, %27  : f32
      memref.store %28, %arg7[%18, %20] : memref<512x512xf32>
      %29 = llvm.add %22, %1 : i64
      %30 = builtin.unrealized_conversion_cast %29 : i64 to index
      cf.br ^bb1(%30 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After GpuNVVMAttachTarget (nvvm-attach-target) //----- //
module attributes {gpu.container_module} {
  llvm.func @matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64, %arg14: !llvm.ptr, %arg15: !llvm.ptr, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: i64) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(512 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i64
    %3 = llvm.mlir.constant(32 : index) : i64
    %4 = llvm.mlir.constant(16 : index) : i64
    %5 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %6 = llvm.insertvalue %arg14, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg15, %6[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.insertvalue %arg16, %7[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %9 = llvm.insertvalue %arg17, %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.insertvalue %arg19, %9[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %arg18, %10[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg20, %11[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = builtin.unrealized_conversion_cast %12 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %14 = llvm.insertvalue %arg7, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg8, %14[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %arg9, %15[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %arg10, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %arg12, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %arg11, %18[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.insertvalue %arg13, %19[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = builtin.unrealized_conversion_cast %20 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %22 = llvm.insertvalue %arg0, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.insertvalue %arg1, %22[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %24 = llvm.insertvalue %arg2, %23[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %25 = llvm.insertvalue %arg3, %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %26 = llvm.insertvalue %arg5, %25[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %27 = llvm.insertvalue %arg4, %26[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %28 = llvm.insertvalue %arg6, %27[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %29 = builtin.unrealized_conversion_cast %28 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %30 = builtin.unrealized_conversion_cast %0 : i64 to index
    %31 = builtin.unrealized_conversion_cast %1 : i64 to index
    %32 = builtin.unrealized_conversion_cast %2 : i64 to index
    %33 = builtin.unrealized_conversion_cast %3 : i64 to index
    %34 = builtin.unrealized_conversion_cast %4 : i64 to index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%34, %33, %32) threads in (%33, %34, %32)  args(%33 : index, %30 : index, %34 : index, %32 : index, %31 : index, %29 : memref<512x512xf32>, %21 : memref<512x512xf32>, %13 : memref<512x512xf32>)
    llvm.return
  }
  llvm.func @_mlir_ciface_matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %17 = llvm.extractvalue %16[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.extractvalue %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.extractvalue %16[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.extractvalue %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.extractvalue %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.extractvalue %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.extractvalue %16[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.call @matmul_memref(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15, %17, %18, %19, %20, %21, %22, %23) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> ()
    llvm.return
  }
  gpu.module @matmul_memref_kernel [#nvvm.target<triple = "nvptx-nvidia-cuda", chip = "sm_80">]  {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %0 = builtin.unrealized_conversion_cast %arg4 : index to i64
      %1 = builtin.unrealized_conversion_cast %arg3 : index to i64
      %2 = builtin.unrealized_conversion_cast %arg2 : index to i64
      %3 = builtin.unrealized_conversion_cast %arg1 : index to i64
      %4 = builtin.unrealized_conversion_cast %arg0 : index to i64
      %block_id_x = gpu.block_id  x
      %5 = builtin.unrealized_conversion_cast %block_id_x : index to i64
      %block_id_y = gpu.block_id  y
      %6 = builtin.unrealized_conversion_cast %block_id_y : index to i64
      %thread_id_x = gpu.thread_id  x
      %7 = builtin.unrealized_conversion_cast %thread_id_x : index to i64
      %thread_id_y = gpu.thread_id  y
      %8 = builtin.unrealized_conversion_cast %thread_id_y : index to i64
      %9 = llvm.mul %5, %4 : i64
      %10 = llvm.add %9, %3 : i64
      %11 = llvm.mul %6, %2 : i64
      %12 = llvm.add %11, %3 : i64
      %13 = llvm.mul %7, %1 : i64
      %14 = llvm.add %13, %3 : i64
      %15 = llvm.mul %8, %1 : i64
      %16 = llvm.add %15, %3 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = builtin.unrealized_conversion_cast %17 : i64 to index
      %19 = llvm.add %16, %12 : i64
      %20 = builtin.unrealized_conversion_cast %19 : i64 to index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%21: index):  // 2 preds: ^bb0, ^bb2
      %22 = builtin.unrealized_conversion_cast %21 : index to i64
      %23 = llvm.icmp "slt" %22, %0 : i64
      llvm.cond_br %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %24 = memref.load %arg5[%18, %21] : memref<512x512xf32>
      %25 = memref.load %arg6[%21, %20] : memref<512x512xf32>
      %26 = memref.load %arg7[%18, %20] : memref<512x512xf32>
      %27 = llvm.fmul %24, %25  : f32
      %28 = llvm.fadd %26, %27  : f32
      memref.store %28, %arg7[%18, %20] : memref<512x512xf32>
      %29 = llvm.add %22, %1 : i64
      %30 = builtin.unrealized_conversion_cast %29 : i64 to index
      cf.br ^bb1(%30 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
module attributes {gpu.container_module} {
  llvm.func @matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64, %arg14: !llvm.ptr, %arg15: !llvm.ptr, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: i64) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(512 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i64
    %3 = llvm.mlir.constant(32 : index) : i64
    %4 = llvm.mlir.constant(16 : index) : i64
    %5 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %6 = llvm.insertvalue %arg14, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg15, %6[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.insertvalue %arg16, %7[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %9 = llvm.insertvalue %arg17, %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.insertvalue %arg19, %9[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %arg18, %10[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg20, %11[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = builtin.unrealized_conversion_cast %12 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %14 = llvm.insertvalue %arg7, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg8, %14[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %arg9, %15[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %arg10, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %arg12, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %arg11, %18[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.insertvalue %arg13, %19[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = builtin.unrealized_conversion_cast %20 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %22 = llvm.insertvalue %arg0, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.insertvalue %arg1, %22[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %24 = llvm.insertvalue %arg2, %23[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %25 = llvm.insertvalue %arg3, %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %26 = llvm.insertvalue %arg5, %25[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %27 = llvm.insertvalue %arg4, %26[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %28 = llvm.insertvalue %arg6, %27[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %29 = builtin.unrealized_conversion_cast %28 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %30 = builtin.unrealized_conversion_cast %0 : i64 to index
    %31 = builtin.unrealized_conversion_cast %1 : i64 to index
    %32 = builtin.unrealized_conversion_cast %2 : i64 to index
    %33 = builtin.unrealized_conversion_cast %3 : i64 to index
    %34 = builtin.unrealized_conversion_cast %4 : i64 to index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%34, %33, %32) threads in (%33, %34, %32)  args(%33 : index, %30 : index, %34 : index, %32 : index, %31 : index, %29 : memref<512x512xf32>, %21 : memref<512x512xf32>, %13 : memref<512x512xf32>)
    llvm.return
  }
  llvm.func @_mlir_ciface_matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %17 = llvm.extractvalue %16[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.extractvalue %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.extractvalue %16[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.extractvalue %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.extractvalue %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.extractvalue %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.extractvalue %16[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.call @matmul_memref(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15, %17, %18, %19, %20, %21, %22, %23) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> ()
    llvm.return
  }
  gpu.module @matmul_memref_kernel [#nvvm.target<triple = "nvptx-nvidia-cuda", chip = "sm_80">]  {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %0 = builtin.unrealized_conversion_cast %arg4 : index to i64
      %1 = builtin.unrealized_conversion_cast %arg3 : index to i64
      %2 = builtin.unrealized_conversion_cast %arg2 : index to i64
      %3 = builtin.unrealized_conversion_cast %arg1 : index to i64
      %4 = builtin.unrealized_conversion_cast %arg0 : index to i64
      %block_id_x = gpu.block_id  x
      %5 = builtin.unrealized_conversion_cast %block_id_x : index to i64
      %block_id_y = gpu.block_id  y
      %6 = builtin.unrealized_conversion_cast %block_id_y : index to i64
      %thread_id_x = gpu.thread_id  x
      %7 = builtin.unrealized_conversion_cast %thread_id_x : index to i64
      %thread_id_y = gpu.thread_id  y
      %8 = builtin.unrealized_conversion_cast %thread_id_y : index to i64
      %9 = llvm.mul %5, %4 : i64
      %10 = llvm.add %9, %3 : i64
      %11 = llvm.mul %6, %2 : i64
      %12 = llvm.add %11, %3 : i64
      %13 = llvm.mul %7, %1 : i64
      %14 = llvm.add %13, %3 : i64
      %15 = llvm.mul %8, %1 : i64
      %16 = llvm.add %15, %3 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = builtin.unrealized_conversion_cast %17 : i64 to index
      %19 = llvm.add %16, %12 : i64
      %20 = builtin.unrealized_conversion_cast %19 : i64 to index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%21: index):  // 2 preds: ^bb0, ^bb2
      %22 = builtin.unrealized_conversion_cast %21 : index to i64
      %23 = llvm.icmp "slt" %22, %0 : i64
      llvm.cond_br %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %24 = memref.load %arg5[%18, %21] : memref<512x512xf32>
      %25 = memref.load %arg6[%21, %20] : memref<512x512xf32>
      %26 = memref.load %arg7[%18, %20] : memref<512x512xf32>
      %27 = llvm.fmul %24, %25  : f32
      %28 = llvm.fadd %26, %27  : f32
      memref.store %28, %arg7[%18, %20] : memref<512x512xf32>
      %29 = llvm.add %22, %1 : i64
      %30 = builtin.unrealized_conversion_cast %29 : i64 to index
      cf.br ^bb1(%30 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After ArithToLLVMConversionPass (convert-arith-to-llvm) //----- //
module attributes {gpu.container_module} {
  llvm.func @matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64, %arg14: !llvm.ptr, %arg15: !llvm.ptr, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: i64) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(512 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i64
    %3 = llvm.mlir.constant(32 : index) : i64
    %4 = llvm.mlir.constant(16 : index) : i64
    %5 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %6 = llvm.insertvalue %arg14, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg15, %6[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.insertvalue %arg16, %7[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %9 = llvm.insertvalue %arg17, %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.insertvalue %arg19, %9[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %arg18, %10[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg20, %11[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = builtin.unrealized_conversion_cast %12 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %14 = llvm.insertvalue %arg7, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg8, %14[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %arg9, %15[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %arg10, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %arg12, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %arg11, %18[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.insertvalue %arg13, %19[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = builtin.unrealized_conversion_cast %20 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %22 = llvm.insertvalue %arg0, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.insertvalue %arg1, %22[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %24 = llvm.insertvalue %arg2, %23[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %25 = llvm.insertvalue %arg3, %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %26 = llvm.insertvalue %arg5, %25[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %27 = llvm.insertvalue %arg4, %26[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %28 = llvm.insertvalue %arg6, %27[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %29 = builtin.unrealized_conversion_cast %28 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %30 = builtin.unrealized_conversion_cast %0 : i64 to index
    %31 = builtin.unrealized_conversion_cast %1 : i64 to index
    %32 = builtin.unrealized_conversion_cast %2 : i64 to index
    %33 = builtin.unrealized_conversion_cast %3 : i64 to index
    %34 = builtin.unrealized_conversion_cast %4 : i64 to index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%34, %33, %32) threads in (%33, %34, %32)  args(%33 : index, %30 : index, %34 : index, %32 : index, %31 : index, %29 : memref<512x512xf32>, %21 : memref<512x512xf32>, %13 : memref<512x512xf32>)
    llvm.return
  }
  llvm.func @_mlir_ciface_matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %17 = llvm.extractvalue %16[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.extractvalue %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.extractvalue %16[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.extractvalue %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.extractvalue %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.extractvalue %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.extractvalue %16[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.call @matmul_memref(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15, %17, %18, %19, %20, %21, %22, %23) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> ()
    llvm.return
  }
  gpu.module @matmul_memref_kernel [#nvvm.target<triple = "nvptx-nvidia-cuda", chip = "sm_80">]  {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %0 = builtin.unrealized_conversion_cast %arg4 : index to i64
      %1 = builtin.unrealized_conversion_cast %arg3 : index to i64
      %2 = builtin.unrealized_conversion_cast %arg2 : index to i64
      %3 = builtin.unrealized_conversion_cast %arg1 : index to i64
      %4 = builtin.unrealized_conversion_cast %arg0 : index to i64
      %block_id_x = gpu.block_id  x
      %5 = builtin.unrealized_conversion_cast %block_id_x : index to i64
      %block_id_y = gpu.block_id  y
      %6 = builtin.unrealized_conversion_cast %block_id_y : index to i64
      %thread_id_x = gpu.thread_id  x
      %7 = builtin.unrealized_conversion_cast %thread_id_x : index to i64
      %thread_id_y = gpu.thread_id  y
      %8 = builtin.unrealized_conversion_cast %thread_id_y : index to i64
      %9 = llvm.mul %5, %4 : i64
      %10 = llvm.add %9, %3 : i64
      %11 = llvm.mul %6, %2 : i64
      %12 = llvm.add %11, %3 : i64
      %13 = llvm.mul %7, %1 : i64
      %14 = llvm.add %13, %3 : i64
      %15 = llvm.mul %8, %1 : i64
      %16 = llvm.add %15, %3 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = builtin.unrealized_conversion_cast %17 : i64 to index
      %19 = llvm.add %16, %12 : i64
      %20 = builtin.unrealized_conversion_cast %19 : i64 to index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%21: index):  // 2 preds: ^bb0, ^bb2
      %22 = builtin.unrealized_conversion_cast %21 : index to i64
      %23 = llvm.icmp "slt" %22, %0 : i64
      llvm.cond_br %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %24 = memref.load %arg5[%18, %21] : memref<512x512xf32>
      %25 = memref.load %arg6[%21, %20] : memref<512x512xf32>
      %26 = memref.load %arg7[%18, %20] : memref<512x512xf32>
      %27 = llvm.fmul %24, %25  : f32
      %28 = llvm.fadd %26, %27  : f32
      memref.store %28, %arg7[%18, %20] : memref<512x512xf32>
      %29 = llvm.add %22, %1 : i64
      %30 = builtin.unrealized_conversion_cast %29 : i64 to index
      cf.br ^bb1(%30 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After ConvertIndexToLLVMPass (convert-index-to-llvm) //----- //
module attributes {gpu.container_module} {
  llvm.func @matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64, %arg14: !llvm.ptr, %arg15: !llvm.ptr, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: i64) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(512 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i64
    %3 = llvm.mlir.constant(32 : index) : i64
    %4 = llvm.mlir.constant(16 : index) : i64
    %5 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %6 = llvm.insertvalue %arg14, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg15, %6[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.insertvalue %arg16, %7[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %9 = llvm.insertvalue %arg17, %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.insertvalue %arg19, %9[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %arg18, %10[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg20, %11[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = builtin.unrealized_conversion_cast %12 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %14 = llvm.insertvalue %arg7, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg8, %14[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %arg9, %15[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %arg10, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %arg12, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %arg11, %18[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.insertvalue %arg13, %19[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = builtin.unrealized_conversion_cast %20 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %22 = llvm.insertvalue %arg0, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.insertvalue %arg1, %22[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %24 = llvm.insertvalue %arg2, %23[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %25 = llvm.insertvalue %arg3, %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %26 = llvm.insertvalue %arg5, %25[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %27 = llvm.insertvalue %arg4, %26[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %28 = llvm.insertvalue %arg6, %27[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %29 = builtin.unrealized_conversion_cast %28 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %30 = builtin.unrealized_conversion_cast %0 : i64 to index
    %31 = builtin.unrealized_conversion_cast %1 : i64 to index
    %32 = builtin.unrealized_conversion_cast %2 : i64 to index
    %33 = builtin.unrealized_conversion_cast %3 : i64 to index
    %34 = builtin.unrealized_conversion_cast %4 : i64 to index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%34, %33, %32) threads in (%33, %34, %32)  args(%33 : index, %30 : index, %34 : index, %32 : index, %31 : index, %29 : memref<512x512xf32>, %21 : memref<512x512xf32>, %13 : memref<512x512xf32>)
    llvm.return
  }
  llvm.func @_mlir_ciface_matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %17 = llvm.extractvalue %16[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.extractvalue %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.extractvalue %16[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.extractvalue %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.extractvalue %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.extractvalue %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.extractvalue %16[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.call @matmul_memref(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15, %17, %18, %19, %20, %21, %22, %23) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> ()
    llvm.return
  }
  gpu.module @matmul_memref_kernel [#nvvm.target<triple = "nvptx-nvidia-cuda", chip = "sm_80">]  {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %0 = builtin.unrealized_conversion_cast %arg4 : index to i64
      %1 = builtin.unrealized_conversion_cast %arg3 : index to i64
      %2 = builtin.unrealized_conversion_cast %arg2 : index to i64
      %3 = builtin.unrealized_conversion_cast %arg1 : index to i64
      %4 = builtin.unrealized_conversion_cast %arg0 : index to i64
      %block_id_x = gpu.block_id  x
      %5 = builtin.unrealized_conversion_cast %block_id_x : index to i64
      %block_id_y = gpu.block_id  y
      %6 = builtin.unrealized_conversion_cast %block_id_y : index to i64
      %thread_id_x = gpu.thread_id  x
      %7 = builtin.unrealized_conversion_cast %thread_id_x : index to i64
      %thread_id_y = gpu.thread_id  y
      %8 = builtin.unrealized_conversion_cast %thread_id_y : index to i64
      %9 = llvm.mul %5, %4 : i64
      %10 = llvm.add %9, %3 : i64
      %11 = llvm.mul %6, %2 : i64
      %12 = llvm.add %11, %3 : i64
      %13 = llvm.mul %7, %1 : i64
      %14 = llvm.add %13, %3 : i64
      %15 = llvm.mul %8, %1 : i64
      %16 = llvm.add %15, %3 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = builtin.unrealized_conversion_cast %17 : i64 to index
      %19 = llvm.add %16, %12 : i64
      %20 = builtin.unrealized_conversion_cast %19 : i64 to index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%21: index):  // 2 preds: ^bb0, ^bb2
      %22 = builtin.unrealized_conversion_cast %21 : index to i64
      %23 = llvm.icmp "slt" %22, %0 : i64
      llvm.cond_br %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %24 = memref.load %arg5[%18, %21] : memref<512x512xf32>
      %25 = memref.load %arg6[%21, %20] : memref<512x512xf32>
      %26 = memref.load %arg7[%18, %20] : memref<512x512xf32>
      %27 = llvm.fmul %24, %25  : f32
      %28 = llvm.fadd %26, %27  : f32
      memref.store %28, %arg7[%18, %20] : memref<512x512xf32>
      %29 = llvm.add %22, %1 : i64
      %30 = builtin.unrealized_conversion_cast %29 : i64 to index
      cf.br ^bb1(%30 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module attributes {gpu.container_module} {
  llvm.func @matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64, %arg14: !llvm.ptr, %arg15: !llvm.ptr, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: i64) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(512 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i64
    %3 = llvm.mlir.constant(32 : index) : i64
    %4 = llvm.mlir.constant(16 : index) : i64
    %5 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %6 = llvm.insertvalue %arg14, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg15, %6[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.insertvalue %arg16, %7[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %9 = llvm.insertvalue %arg17, %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.insertvalue %arg19, %9[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %arg18, %10[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg20, %11[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = builtin.unrealized_conversion_cast %12 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %14 = llvm.insertvalue %arg7, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg8, %14[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %arg9, %15[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %arg10, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %arg12, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %arg11, %18[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.insertvalue %arg13, %19[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = builtin.unrealized_conversion_cast %20 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %22 = llvm.insertvalue %arg0, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.insertvalue %arg1, %22[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %24 = llvm.insertvalue %arg2, %23[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %25 = llvm.insertvalue %arg3, %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %26 = llvm.insertvalue %arg5, %25[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %27 = llvm.insertvalue %arg4, %26[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %28 = llvm.insertvalue %arg6, %27[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %29 = builtin.unrealized_conversion_cast %28 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %30 = builtin.unrealized_conversion_cast %0 : i64 to index
    %31 = builtin.unrealized_conversion_cast %1 : i64 to index
    %32 = builtin.unrealized_conversion_cast %2 : i64 to index
    %33 = builtin.unrealized_conversion_cast %3 : i64 to index
    %34 = builtin.unrealized_conversion_cast %4 : i64 to index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%34, %33, %32) threads in (%33, %34, %32)  args(%33 : index, %30 : index, %34 : index, %32 : index, %31 : index, %29 : memref<512x512xf32>, %21 : memref<512x512xf32>, %13 : memref<512x512xf32>)
    llvm.return
  }
  llvm.func @_mlir_ciface_matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %17 = llvm.extractvalue %16[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.extractvalue %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.extractvalue %16[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.extractvalue %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.extractvalue %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.extractvalue %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.extractvalue %16[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.call @matmul_memref(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15, %17, %18, %19, %20, %21, %22, %23) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> ()
    llvm.return
  }
  gpu.module @matmul_memref_kernel [#nvvm.target<triple = "nvptx-nvidia-cuda", chip = "sm_80">]  {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %0 = builtin.unrealized_conversion_cast %arg4 : index to i64
      %1 = builtin.unrealized_conversion_cast %arg3 : index to i64
      %2 = builtin.unrealized_conversion_cast %arg2 : index to i64
      %3 = builtin.unrealized_conversion_cast %arg1 : index to i64
      %4 = builtin.unrealized_conversion_cast %arg0 : index to i64
      %block_id_x = gpu.block_id  x
      %5 = builtin.unrealized_conversion_cast %block_id_x : index to i64
      %block_id_y = gpu.block_id  y
      %6 = builtin.unrealized_conversion_cast %block_id_y : index to i64
      %thread_id_x = gpu.thread_id  x
      %7 = builtin.unrealized_conversion_cast %thread_id_x : index to i64
      %thread_id_y = gpu.thread_id  y
      %8 = builtin.unrealized_conversion_cast %thread_id_y : index to i64
      %9 = llvm.mul %5, %4 : i64
      %10 = llvm.add %9, %3 : i64
      %11 = llvm.mul %6, %2 : i64
      %12 = llvm.add %11, %3 : i64
      %13 = llvm.mul %7, %1 : i64
      %14 = llvm.add %13, %3 : i64
      %15 = llvm.mul %8, %1 : i64
      %16 = llvm.add %15, %3 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = builtin.unrealized_conversion_cast %17 : i64 to index
      %19 = llvm.add %16, %12 : i64
      %20 = builtin.unrealized_conversion_cast %19 : i64 to index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%21: index):  // 2 preds: ^bb0, ^bb2
      %22 = builtin.unrealized_conversion_cast %21 : index to i64
      %23 = llvm.icmp "slt" %22, %0 : i64
      llvm.cond_br %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %24 = memref.load %arg5[%18, %21] : memref<512x512xf32>
      %25 = memref.load %arg6[%21, %20] : memref<512x512xf32>
      %26 = memref.load %arg7[%18, %20] : memref<512x512xf32>
      %27 = llvm.fmul %24, %25  : f32
      %28 = llvm.fadd %26, %27  : f32
      memref.store %28, %arg7[%18, %20] : memref<512x512xf32>
      %29 = llvm.add %22, %1 : i64
      %30 = builtin.unrealized_conversion_cast %29 : i64 to index
      cf.br ^bb1(%30 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After CSE (cse) //----- //
module attributes {gpu.container_module} {
  llvm.func @matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64, %arg14: !llvm.ptr, %arg15: !llvm.ptr, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: i64) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(512 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i64
    %3 = llvm.mlir.constant(32 : index) : i64
    %4 = llvm.mlir.constant(16 : index) : i64
    %5 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %6 = llvm.insertvalue %arg14, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg15, %6[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.insertvalue %arg16, %7[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %9 = llvm.insertvalue %arg17, %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.insertvalue %arg19, %9[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %arg18, %10[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg20, %11[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = builtin.unrealized_conversion_cast %12 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %14 = llvm.insertvalue %arg7, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg8, %14[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %arg9, %15[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %arg10, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %arg12, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %arg11, %18[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.insertvalue %arg13, %19[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = builtin.unrealized_conversion_cast %20 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %22 = llvm.insertvalue %arg0, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.insertvalue %arg1, %22[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %24 = llvm.insertvalue %arg2, %23[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %25 = llvm.insertvalue %arg3, %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %26 = llvm.insertvalue %arg5, %25[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %27 = llvm.insertvalue %arg4, %26[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %28 = llvm.insertvalue %arg6, %27[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %29 = builtin.unrealized_conversion_cast %28 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %30 = builtin.unrealized_conversion_cast %0 : i64 to index
    %31 = builtin.unrealized_conversion_cast %1 : i64 to index
    %32 = builtin.unrealized_conversion_cast %2 : i64 to index
    %33 = builtin.unrealized_conversion_cast %3 : i64 to index
    %34 = builtin.unrealized_conversion_cast %4 : i64 to index
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%34, %33, %32) threads in (%33, %34, %32)  args(%33 : index, %30 : index, %34 : index, %32 : index, %31 : index, %29 : memref<512x512xf32>, %21 : memref<512x512xf32>, %13 : memref<512x512xf32>)
    llvm.return
  }
  llvm.func @_mlir_ciface_matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %17 = llvm.extractvalue %16[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.extractvalue %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.extractvalue %16[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.extractvalue %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.extractvalue %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.extractvalue %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.extractvalue %16[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.call @matmul_memref(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15, %17, %18, %19, %20, %21, %22, %23) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> ()
    llvm.return
  }
  gpu.module @matmul_memref_kernel [#nvvm.target<triple = "nvptx-nvidia-cuda", chip = "sm_80">]  {
    gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
      %0 = builtin.unrealized_conversion_cast %arg4 : index to i64
      %1 = builtin.unrealized_conversion_cast %arg3 : index to i64
      %2 = builtin.unrealized_conversion_cast %arg2 : index to i64
      %3 = builtin.unrealized_conversion_cast %arg1 : index to i64
      %4 = builtin.unrealized_conversion_cast %arg0 : index to i64
      %block_id_x = gpu.block_id  x
      %5 = builtin.unrealized_conversion_cast %block_id_x : index to i64
      %block_id_y = gpu.block_id  y
      %6 = builtin.unrealized_conversion_cast %block_id_y : index to i64
      %thread_id_x = gpu.thread_id  x
      %7 = builtin.unrealized_conversion_cast %thread_id_x : index to i64
      %thread_id_y = gpu.thread_id  y
      %8 = builtin.unrealized_conversion_cast %thread_id_y : index to i64
      %9 = llvm.mul %5, %4 : i64
      %10 = llvm.add %9, %3 : i64
      %11 = llvm.mul %6, %2 : i64
      %12 = llvm.add %11, %3 : i64
      %13 = llvm.mul %7, %1 : i64
      %14 = llvm.add %13, %3 : i64
      %15 = llvm.mul %8, %1 : i64
      %16 = llvm.add %15, %3 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = builtin.unrealized_conversion_cast %17 : i64 to index
      %19 = llvm.add %16, %12 : i64
      %20 = builtin.unrealized_conversion_cast %19 : i64 to index
      cf.br ^bb1(%arg1 : index)
    ^bb1(%21: index):  // 2 preds: ^bb0, ^bb2
      %22 = builtin.unrealized_conversion_cast %21 : index to i64
      %23 = llvm.icmp "slt" %22, %0 : i64
      llvm.cond_br %23, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %24 = memref.load %arg5[%18, %21] : memref<512x512xf32>
      %25 = memref.load %arg6[%21, %20] : memref<512x512xf32>
      %26 = memref.load %arg7[%18, %20] : memref<512x512xf32>
      %27 = llvm.fmul %24, %25  : f32
      %28 = llvm.fadd %26, %27  : f32
      memref.store %28, %arg7[%18, %20] : memref<512x512xf32>
      %29 = llvm.add %22, %1 : i64
      %30 = builtin.unrealized_conversion_cast %29 : i64 to index
      cf.br ^bb1(%30 : index)
    ^bb3:  // pred: ^bb1
      gpu.return
    }
  }
}


// -----// IR Dump After StripDebugInfo (strip-debuginfo) //----- //
gpu.module @matmul_memref_kernel [#nvvm.target<triple = "nvptx-nvidia-cuda", chip = "sm_80">]  {
  gpu.func @matmul_memref_kernel(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<512x512xf32>, %arg6: memref<512x512xf32>, %arg7: memref<512x512xf32>) kernel attributes {known_block_size = array<i32: 32, 16, 1>, known_grid_size = array<i32: 16, 32, 1>} {
    %0 = builtin.unrealized_conversion_cast %arg4 : index to i64
    %1 = builtin.unrealized_conversion_cast %arg3 : index to i64
    %2 = builtin.unrealized_conversion_cast %arg2 : index to i64
    %3 = builtin.unrealized_conversion_cast %arg1 : index to i64
    %4 = builtin.unrealized_conversion_cast %arg0 : index to i64
    %block_id_x = gpu.block_id  x
    %5 = builtin.unrealized_conversion_cast %block_id_x : index to i64
    %block_id_y = gpu.block_id  y
    %6 = builtin.unrealized_conversion_cast %block_id_y : index to i64
    %thread_id_x = gpu.thread_id  x
    %7 = builtin.unrealized_conversion_cast %thread_id_x : index to i64
    %thread_id_y = gpu.thread_id  y
    %8 = builtin.unrealized_conversion_cast %thread_id_y : index to i64
    %9 = llvm.mul %5, %4 : i64
    %10 = llvm.add %9, %3 : i64
    %11 = llvm.mul %6, %2 : i64
    %12 = llvm.add %11, %3 : i64
    %13 = llvm.mul %7, %1 : i64
    %14 = llvm.add %13, %3 : i64
    %15 = llvm.mul %8, %1 : i64
    %16 = llvm.add %15, %3 : i64
    %17 = llvm.add %14, %10 : i64
    %18 = builtin.unrealized_conversion_cast %17 : i64 to index
    %19 = llvm.add %16, %12 : i64
    %20 = builtin.unrealized_conversion_cast %19 : i64 to index
    cf.br ^bb1(%arg1 : index)
  ^bb1(%21: index):  // 2 preds: ^bb0, ^bb2
    %22 = builtin.unrealized_conversion_cast %21 : index to i64
    %23 = llvm.icmp "slt" %22, %0 : i64
    llvm.cond_br %23, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %24 = memref.load %arg5[%18, %21] : memref<512x512xf32>
    %25 = memref.load %arg6[%21, %20] : memref<512x512xf32>
    %26 = memref.load %arg7[%18, %20] : memref<512x512xf32>
    %27 = llvm.fmul %24, %25  : f32
    %28 = llvm.fadd %26, %27  : f32
    memref.store %28, %arg7[%18, %20] : memref<512x512xf32>
    %29 = llvm.add %22, %1 : i64
    %30 = builtin.unrealized_conversion_cast %29 : i64 to index
    cf.br ^bb1(%30 : index)
  ^bb3:  // pred: ^bb1
    gpu.return
  }
}

// -----// IR Dump After ConvertGpuOpsToNVVMOps (convert-gpu-to-nvvm) //----- //
gpu.module @matmul_memref_kernel [#nvvm.target<triple = "nvptx-nvidia-cuda", chip = "sm_80">]  {
  llvm.func @matmul_memref_kernel(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: !llvm.ptr, %arg6: !llvm.ptr, %arg7: i64, %arg8: i64, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: !llvm.ptr, %arg13: !llvm.ptr, %arg14: i64, %arg15: i64, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: !llvm.ptr, %arg20: !llvm.ptr, %arg21: i64, %arg22: i64, %arg23: i64, %arg24: i64, %arg25: i64) attributes {gpu.kernel, gpu.known_block_size = array<i32: 32, 16, 1>, gpu.known_grid_size = array<i32: 16, 32, 1>, nvvm.kernel, nvvm.maxntid = array<i32: 32, 16, 1>} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.insertvalue %arg19, %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.insertvalue %arg20, %1[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.insertvalue %arg21, %2[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.insertvalue %arg22, %3[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.insertvalue %arg24, %4[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.insertvalue %arg23, %5[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg25, %6[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = builtin.unrealized_conversion_cast %7 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %9 = builtin.unrealized_conversion_cast %8 : memref<512x512xf32> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %10 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %11 = llvm.insertvalue %arg12, %10[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg13, %11[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.insertvalue %arg14, %12[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.insertvalue %arg15, %13[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg17, %14[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %arg16, %15[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %arg18, %16[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = builtin.unrealized_conversion_cast %17 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %19 = builtin.unrealized_conversion_cast %18 : memref<512x512xf32> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %20 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %21 = llvm.insertvalue %arg5, %20[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.insertvalue %arg6, %21[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.insertvalue %arg7, %22[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %24 = llvm.insertvalue %arg8, %23[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %25 = llvm.insertvalue %arg10, %24[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %26 = llvm.insertvalue %arg9, %25[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %27 = llvm.insertvalue %arg11, %26[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %28 = builtin.unrealized_conversion_cast %27 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %29 = builtin.unrealized_conversion_cast %28 : memref<512x512xf32> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %30 = builtin.unrealized_conversion_cast %arg4 : i64 to index
    %31 = builtin.unrealized_conversion_cast %arg3 : i64 to index
    %32 = builtin.unrealized_conversion_cast %arg2 : i64 to index
    %33 = builtin.unrealized_conversion_cast %arg1 : i64 to index
    %34 = builtin.unrealized_conversion_cast %arg0 : i64 to index
    %35 = builtin.unrealized_conversion_cast %30 : index to i64
    %36 = builtin.unrealized_conversion_cast %31 : index to i64
    %37 = builtin.unrealized_conversion_cast %32 : index to i64
    %38 = builtin.unrealized_conversion_cast %33 : index to i64
    %39 = builtin.unrealized_conversion_cast %34 : index to i64
    %40 = nvvm.read.ptx.sreg.ctaid.x : i32
    %41 = llvm.sext %40 : i32 to i64
    %42 = builtin.unrealized_conversion_cast %41 : i64 to index
    %43 = builtin.unrealized_conversion_cast %42 : index to i64
    %44 = nvvm.read.ptx.sreg.ctaid.y : i32
    %45 = llvm.sext %44 : i32 to i64
    %46 = builtin.unrealized_conversion_cast %45 : i64 to index
    %47 = builtin.unrealized_conversion_cast %46 : index to i64
    %48 = nvvm.read.ptx.sreg.tid.x : i32
    %49 = llvm.sext %48 : i32 to i64
    %50 = builtin.unrealized_conversion_cast %49 : i64 to index
    %51 = builtin.unrealized_conversion_cast %50 : index to i64
    %52 = nvvm.read.ptx.sreg.tid.y : i32
    %53 = llvm.sext %52 : i32 to i64
    %54 = builtin.unrealized_conversion_cast %53 : i64 to index
    %55 = builtin.unrealized_conversion_cast %54 : index to i64
    %56 = llvm.mul %43, %39 : i64
    %57 = llvm.add %56, %38 : i64
    %58 = llvm.mul %47, %37 : i64
    %59 = llvm.add %58, %38 : i64
    %60 = llvm.mul %51, %36 : i64
    %61 = llvm.add %60, %38 : i64
    %62 = llvm.mul %55, %36 : i64
    %63 = llvm.add %62, %38 : i64
    %64 = llvm.add %61, %57 : i64
    %65 = builtin.unrealized_conversion_cast %64 : i64 to index
    %66 = llvm.add %63, %59 : i64
    %67 = builtin.unrealized_conversion_cast %66 : i64 to index
    llvm.br ^bb1(%arg1 : i64)
  ^bb1(%68: i64):  // 2 preds: ^bb0, ^bb2
    %69 = builtin.unrealized_conversion_cast %68 : i64 to index
    %70 = builtin.unrealized_conversion_cast %69 : index to i64
    %71 = llvm.icmp "slt" %70, %35 : i64
    llvm.cond_br %71, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %72 = llvm.extractvalue %29[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %73 = llvm.mlir.constant(512 : index) : i64
    %74 = llvm.mul %64, %73 : i64
    %75 = llvm.add %74, %68 : i64
    %76 = llvm.getelementptr %72[%75] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %77 = llvm.load %76 : !llvm.ptr -> f32
    %78 = llvm.extractvalue %19[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %79 = llvm.mlir.constant(512 : index) : i64
    %80 = llvm.mul %68, %79 : i64
    %81 = llvm.add %80, %66 : i64
    %82 = llvm.getelementptr %78[%81] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %83 = llvm.load %82 : !llvm.ptr -> f32
    %84 = llvm.extractvalue %9[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %85 = llvm.mlir.constant(512 : index) : i64
    %86 = llvm.mul %64, %85 : i64
    %87 = llvm.add %86, %66 : i64
    %88 = llvm.getelementptr %84[%87] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %89 = llvm.load %88 : !llvm.ptr -> f32
    %90 = llvm.fmul %77, %83  : f32
    %91 = llvm.fadd %89, %90  : f32
    %92 = llvm.extractvalue %9[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %93 = llvm.mlir.constant(512 : index) : i64
    %94 = llvm.mul %64, %93 : i64
    %95 = llvm.add %94, %66 : i64
    %96 = llvm.getelementptr %92[%95] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %91, %96 : f32, !llvm.ptr
    %97 = llvm.add %70, %36 : i64
    %98 = builtin.unrealized_conversion_cast %97 : i64 to index
    llvm.br ^bb1(%97 : i64)
  ^bb3:  // pred: ^bb1
    llvm.return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
gpu.module @matmul_memref_kernel [#nvvm.target<triple = "nvptx-nvidia-cuda", chip = "sm_80">]  {
  llvm.func @matmul_memref_kernel(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: !llvm.ptr, %arg6: !llvm.ptr, %arg7: i64, %arg8: i64, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: !llvm.ptr, %arg13: !llvm.ptr, %arg14: i64, %arg15: i64, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: !llvm.ptr, %arg20: !llvm.ptr, %arg21: i64, %arg22: i64, %arg23: i64, %arg24: i64, %arg25: i64) attributes {gpu.kernel, gpu.known_block_size = array<i32: 32, 16, 1>, gpu.known_grid_size = array<i32: 16, 32, 1>, nvvm.kernel, nvvm.maxntid = array<i32: 32, 16, 1>} {
    %0 = llvm.mlir.constant(512 : index) : i64
    %1 = nvvm.read.ptx.sreg.ctaid.x : i32
    %2 = llvm.sext %1 : i32 to i64
    %3 = nvvm.read.ptx.sreg.ctaid.y : i32
    %4 = llvm.sext %3 : i32 to i64
    %5 = nvvm.read.ptx.sreg.tid.x : i32
    %6 = llvm.sext %5 : i32 to i64
    %7 = nvvm.read.ptx.sreg.tid.y : i32
    %8 = llvm.sext %7 : i32 to i64
    %9 = llvm.mul %2, %arg0 : i64
    %10 = llvm.add %9, %arg1 : i64
    %11 = llvm.mul %4, %arg2 : i64
    %12 = llvm.add %11, %arg1 : i64
    %13 = llvm.mul %6, %arg3 : i64
    %14 = llvm.add %13, %arg1 : i64
    %15 = llvm.mul %8, %arg3 : i64
    %16 = llvm.add %15, %arg1 : i64
    %17 = llvm.add %14, %10 : i64
    %18 = llvm.add %16, %12 : i64
    llvm.br ^bb1(%arg1 : i64)
  ^bb1(%19: i64):  // 2 preds: ^bb0, ^bb2
    %20 = llvm.icmp "slt" %19, %arg4 : i64
    llvm.cond_br %20, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %21 = llvm.mul %17, %0 : i64
    %22 = llvm.add %21, %19 : i64
    %23 = llvm.getelementptr %arg6[%22] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %24 = llvm.load %23 : !llvm.ptr -> f32
    %25 = llvm.mul %19, %0 : i64
    %26 = llvm.add %25, %18 : i64
    %27 = llvm.getelementptr %arg13[%26] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %28 = llvm.load %27 : !llvm.ptr -> f32
    %29 = llvm.mul %17, %0 : i64
    %30 = llvm.add %29, %18 : i64
    %31 = llvm.getelementptr %arg20[%30] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %32 = llvm.load %31 : !llvm.ptr -> f32
    %33 = llvm.fmul %24, %28  : f32
    %34 = llvm.fadd %32, %33  : f32
    %35 = llvm.mul %17, %0 : i64
    %36 = llvm.add %35, %18 : i64
    %37 = llvm.getelementptr %arg20[%36] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %34, %37 : f32, !llvm.ptr
    %38 = llvm.add %19, %arg3 : i64
    llvm.br ^bb1(%38 : i64)
  ^bb3:  // pred: ^bb1
    llvm.return
  }
}

// -----// IR Dump After CSE (cse) //----- //
gpu.module @matmul_memref_kernel [#nvvm.target<triple = "nvptx-nvidia-cuda", chip = "sm_80">]  {
  llvm.func @matmul_memref_kernel(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: !llvm.ptr, %arg6: !llvm.ptr, %arg7: i64, %arg8: i64, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: !llvm.ptr, %arg13: !llvm.ptr, %arg14: i64, %arg15: i64, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: !llvm.ptr, %arg20: !llvm.ptr, %arg21: i64, %arg22: i64, %arg23: i64, %arg24: i64, %arg25: i64) attributes {gpu.kernel, gpu.known_block_size = array<i32: 32, 16, 1>, gpu.known_grid_size = array<i32: 16, 32, 1>, nvvm.kernel, nvvm.maxntid = array<i32: 32, 16, 1>} {
    %0 = llvm.mlir.constant(512 : index) : i64
    %1 = nvvm.read.ptx.sreg.ctaid.x : i32
    %2 = llvm.sext %1 : i32 to i64
    %3 = nvvm.read.ptx.sreg.ctaid.y : i32
    %4 = llvm.sext %3 : i32 to i64
    %5 = nvvm.read.ptx.sreg.tid.x : i32
    %6 = llvm.sext %5 : i32 to i64
    %7 = nvvm.read.ptx.sreg.tid.y : i32
    %8 = llvm.sext %7 : i32 to i64
    %9 = llvm.mul %2, %arg0 : i64
    %10 = llvm.add %9, %arg1 : i64
    %11 = llvm.mul %4, %arg2 : i64
    %12 = llvm.add %11, %arg1 : i64
    %13 = llvm.mul %6, %arg3 : i64
    %14 = llvm.add %13, %arg1 : i64
    %15 = llvm.mul %8, %arg3 : i64
    %16 = llvm.add %15, %arg1 : i64
    %17 = llvm.add %14, %10 : i64
    %18 = llvm.add %16, %12 : i64
    llvm.br ^bb1(%arg1 : i64)
  ^bb1(%19: i64):  // 2 preds: ^bb0, ^bb2
    %20 = llvm.icmp "slt" %19, %arg4 : i64
    llvm.cond_br %20, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %21 = llvm.mul %17, %0 : i64
    %22 = llvm.add %21, %19 : i64
    %23 = llvm.getelementptr %arg6[%22] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %24 = llvm.load %23 : !llvm.ptr -> f32
    %25 = llvm.mul %19, %0 : i64
    %26 = llvm.add %25, %18 : i64
    %27 = llvm.getelementptr %arg13[%26] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %28 = llvm.load %27 : !llvm.ptr -> f32
    %29 = llvm.add %21, %18 : i64
    %30 = llvm.getelementptr %arg20[%29] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %31 = llvm.load %30 : !llvm.ptr -> f32
    %32 = llvm.fmul %24, %28  : f32
    %33 = llvm.fadd %31, %32  : f32
    llvm.store %33, %30 : f32, !llvm.ptr
    %34 = llvm.add %19, %arg3 : i64
    llvm.br ^bb1(%34 : i64)
  ^bb3:  // pred: ^bb1
    llvm.return
  }
}

// -----// IR Dump After ReconcileUnrealizedCasts (reconcile-unrealized-casts) //----- //
gpu.module @matmul_memref_kernel [#nvvm.target<triple = "nvptx-nvidia-cuda", chip = "sm_80">]  {
  llvm.func @matmul_memref_kernel(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: !llvm.ptr, %arg6: !llvm.ptr, %arg7: i64, %arg8: i64, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: !llvm.ptr, %arg13: !llvm.ptr, %arg14: i64, %arg15: i64, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: !llvm.ptr, %arg20: !llvm.ptr, %arg21: i64, %arg22: i64, %arg23: i64, %arg24: i64, %arg25: i64) attributes {gpu.kernel, gpu.known_block_size = array<i32: 32, 16, 1>, gpu.known_grid_size = array<i32: 16, 32, 1>, nvvm.kernel, nvvm.maxntid = array<i32: 32, 16, 1>} {
    %0 = llvm.mlir.constant(512 : index) : i64
    %1 = nvvm.read.ptx.sreg.ctaid.x : i32
    %2 = llvm.sext %1 : i32 to i64
    %3 = nvvm.read.ptx.sreg.ctaid.y : i32
    %4 = llvm.sext %3 : i32 to i64
    %5 = nvvm.read.ptx.sreg.tid.x : i32
    %6 = llvm.sext %5 : i32 to i64
    %7 = nvvm.read.ptx.sreg.tid.y : i32
    %8 = llvm.sext %7 : i32 to i64
    %9 = llvm.mul %2, %arg0 : i64
    %10 = llvm.add %9, %arg1 : i64
    %11 = llvm.mul %4, %arg2 : i64
    %12 = llvm.add %11, %arg1 : i64
    %13 = llvm.mul %6, %arg3 : i64
    %14 = llvm.add %13, %arg1 : i64
    %15 = llvm.mul %8, %arg3 : i64
    %16 = llvm.add %15, %arg1 : i64
    %17 = llvm.add %14, %10 : i64
    %18 = llvm.add %16, %12 : i64
    llvm.br ^bb1(%arg1 : i64)
  ^bb1(%19: i64):  // 2 preds: ^bb0, ^bb2
    %20 = llvm.icmp "slt" %19, %arg4 : i64
    llvm.cond_br %20, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %21 = llvm.mul %17, %0 : i64
    %22 = llvm.add %21, %19 : i64
    %23 = llvm.getelementptr %arg6[%22] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %24 = llvm.load %23 : !llvm.ptr -> f32
    %25 = llvm.mul %19, %0 : i64
    %26 = llvm.add %25, %18 : i64
    %27 = llvm.getelementptr %arg13[%26] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %28 = llvm.load %27 : !llvm.ptr -> f32
    %29 = llvm.add %21, %18 : i64
    %30 = llvm.getelementptr %arg20[%29] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %31 = llvm.load %30 : !llvm.ptr -> f32
    %32 = llvm.fmul %24, %28  : f32
    %33 = llvm.fadd %31, %32  : f32
    llvm.store %33, %30 : f32, !llvm.ptr
    %34 = llvm.add %19, %arg3 : i64
    llvm.br ^bb1(%34 : i64)
  ^bb3:  // pred: ^bb1
    llvm.return
  }
}

// -----// IR Dump After GpuToLLVMConversionPass (gpu-to-llvm) //----- //
module attributes {gpu.container_module} {
  llvm.func @matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64, %arg14: !llvm.ptr, %arg15: !llvm.ptr, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: i64) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(512 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i64
    %3 = llvm.mlir.constant(32 : index) : i64
    %4 = llvm.mlir.constant(16 : index) : i64
    %5 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %6 = llvm.insertvalue %arg14, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg15, %6[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.insertvalue %arg16, %7[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %9 = llvm.insertvalue %arg17, %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.insertvalue %arg19, %9[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %arg18, %10[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg20, %11[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = builtin.unrealized_conversion_cast %12 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %14 = llvm.insertvalue %arg7, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg8, %14[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %arg9, %15[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %arg10, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %arg12, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %arg11, %18[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.insertvalue %arg13, %19[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = builtin.unrealized_conversion_cast %20 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %22 = llvm.insertvalue %arg0, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.insertvalue %arg1, %22[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %24 = llvm.insertvalue %arg2, %23[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %25 = llvm.insertvalue %arg3, %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %26 = llvm.insertvalue %arg5, %25[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %27 = llvm.insertvalue %arg4, %26[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %28 = llvm.insertvalue %arg6, %27[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %29 = builtin.unrealized_conversion_cast %28 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %30 = builtin.unrealized_conversion_cast %0 : i64 to index
    %31 = builtin.unrealized_conversion_cast %1 : i64 to index
    %32 = builtin.unrealized_conversion_cast %2 : i64 to index
    %33 = builtin.unrealized_conversion_cast %3 : i64 to index
    %34 = builtin.unrealized_conversion_cast %4 : i64 to index
    %35 = llvm.extractvalue %28[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %36 = llvm.extractvalue %20[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %37 = llvm.extractvalue %12[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%4, %3, %2) threads in (%3, %4, %2) : i64 args(%3 : i64, %0 : i64, %4 : i64, %2 : i64, %1 : i64, %35 : !llvm.ptr, %36 : !llvm.ptr, %37 : !llvm.ptr)
    llvm.return
  }
  llvm.func @_mlir_ciface_matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %17 = llvm.extractvalue %16[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.extractvalue %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.extractvalue %16[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.extractvalue %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.extractvalue %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.extractvalue %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.extractvalue %16[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.call @matmul_memref(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15, %17, %18, %19, %20, %21, %22, %23) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> ()
    llvm.return
  }
  gpu.module @matmul_memref_kernel [#nvvm.target<triple = "nvptx-nvidia-cuda", chip = "sm_80">]  {
    llvm.func @matmul_memref_kernel(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: !llvm.ptr, %arg6: !llvm.ptr, %arg7: i64, %arg8: i64, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: !llvm.ptr, %arg13: !llvm.ptr, %arg14: i64, %arg15: i64, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: !llvm.ptr, %arg20: !llvm.ptr, %arg21: i64, %arg22: i64, %arg23: i64, %arg24: i64, %arg25: i64) attributes {gpu.kernel, gpu.known_block_size = array<i32: 32, 16, 1>, gpu.known_grid_size = array<i32: 16, 32, 1>, nvvm.kernel, nvvm.maxntid = array<i32: 32, 16, 1>} {
      %0 = llvm.mlir.constant(512 : index) : i64
      %1 = nvvm.read.ptx.sreg.ctaid.x : i32
      %2 = llvm.sext %1 : i32 to i64
      %3 = nvvm.read.ptx.sreg.ctaid.y : i32
      %4 = llvm.sext %3 : i32 to i64
      %5 = nvvm.read.ptx.sreg.tid.x : i32
      %6 = llvm.sext %5 : i32 to i64
      %7 = nvvm.read.ptx.sreg.tid.y : i32
      %8 = llvm.sext %7 : i32 to i64
      %9 = llvm.mul %2, %arg0 : i64
      %10 = llvm.add %9, %arg1 : i64
      %11 = llvm.mul %4, %arg2 : i64
      %12 = llvm.add %11, %arg1 : i64
      %13 = llvm.mul %6, %arg3 : i64
      %14 = llvm.add %13, %arg1 : i64
      %15 = llvm.mul %8, %arg3 : i64
      %16 = llvm.add %15, %arg1 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = llvm.add %16, %12 : i64
      llvm.br ^bb1(%arg1 : i64)
    ^bb1(%19: i64):  // 2 preds: ^bb0, ^bb2
      %20 = llvm.icmp "slt" %19, %arg4 : i64
      llvm.cond_br %20, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %21 = llvm.mul %17, %0 : i64
      %22 = llvm.add %21, %19 : i64
      %23 = llvm.getelementptr %arg6[%22] : (!llvm.ptr, i64) -> !llvm.ptr, f32
      %24 = llvm.load %23 : !llvm.ptr -> f32
      %25 = llvm.mul %19, %0 : i64
      %26 = llvm.add %25, %18 : i64
      %27 = llvm.getelementptr %arg13[%26] : (!llvm.ptr, i64) -> !llvm.ptr, f32
      %28 = llvm.load %27 : !llvm.ptr -> f32
      %29 = llvm.add %21, %18 : i64
      %30 = llvm.getelementptr %arg20[%29] : (!llvm.ptr, i64) -> !llvm.ptr, f32
      %31 = llvm.load %30 : !llvm.ptr -> f32
      %32 = llvm.fmul %24, %28  : f32
      %33 = llvm.fadd %31, %32  : f32
      llvm.store %33, %30 : f32, !llvm.ptr
      %34 = llvm.add %19, %arg3 : i64
      llvm.br ^bb1(%34 : i64)
    ^bb3:  // pred: ^bb1
      llvm.return
    }
  }
}


<unknown>:0: error: `ptxas` invocation failed. Log:
ptxas warning :  64 Bit host architecture (--machine) being used mismatches with .address_size of 32 bits
ptxas fatal   :  32-Bit compilation is no longer supported

<unknown>:0: error: An error happened while serializing the module.
<unknown>:0: note: see current operation: 
"gpu.module"() <{sym_name = "matmul_memref_kernel", targets = [#nvvm.target<triple = "nvptx-nvidia-cuda", chip = "sm_80">]}> ({
  "llvm.func"() <{CConv = #llvm.cconv<ccc>, function_type = !llvm.func<void (i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64)>, linkage = #llvm.linkage<external>, sym_name = "matmul_memref_kernel", visibility_ = 0 : i64}> ({
  ^bb0(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: !llvm.ptr, %arg6: !llvm.ptr, %arg7: i64, %arg8: i64, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: !llvm.ptr, %arg13: !llvm.ptr, %arg14: i64, %arg15: i64, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: !llvm.ptr, %arg20: !llvm.ptr, %arg21: i64, %arg22: i64, %arg23: i64, %arg24: i64, %arg25: i64):
    %0 = "llvm.mlir.constant"() <{value = 512 : index}> : () -> i64
    %1 = "nvvm.read.ptx.sreg.ctaid.x"() : () -> i32
    %2 = "llvm.sext"(%1) : (i32) -> i64
    %3 = "nvvm.read.ptx.sreg.ctaid.y"() : () -> i32
    %4 = "llvm.sext"(%3) : (i32) -> i64
    %5 = "nvvm.read.ptx.sreg.tid.x"() : () -> i32
    %6 = "llvm.sext"(%5) : (i32) -> i64
    %7 = "nvvm.read.ptx.sreg.tid.y"() : () -> i32
    %8 = "llvm.sext"(%7) : (i32) -> i64
    %9 = "llvm.mul"(%2, %arg0) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64
    %10 = "llvm.add"(%9, %arg1) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64
    %11 = "llvm.mul"(%4, %arg2) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64
    %12 = "llvm.add"(%11, %arg1) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64
    %13 = "llvm.mul"(%6, %arg3) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64
    %14 = "llvm.add"(%13, %arg1) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64
    %15 = "llvm.mul"(%8, %arg3) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64
    %16 = "llvm.add"(%15, %arg1) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64
    %17 = "llvm.add"(%14, %10) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64
    %18 = "llvm.add"(%16, %12) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64
    "llvm.br"(%arg1)[^bb1] : (i64) -> ()
  ^bb1(%19: i64):  // 2 preds: ^bb0, ^bb2
    %20 = "llvm.icmp"(%19, %arg4) <{predicate = 2 : i64}> : (i64, i64) -> i1
    "llvm.cond_br"(%20)[^bb2, ^bb3] <{operandSegmentSizes = array<i32: 1, 0, 0>}> : (i1) -> ()
  ^bb2:  // pred: ^bb1
    %21 = "llvm.mul"(%17, %0) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64
    %22 = "llvm.add"(%21, %19) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64
    %23 = "llvm.getelementptr"(%arg6, %22) <{elem_type = f32, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr
    %24 = "llvm.load"(%23) <{ordering = 0 : i64}> : (!llvm.ptr) -> f32
    %25 = "llvm.mul"(%19, %0) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64
    %26 = "llvm.add"(%25, %18) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64
    %27 = "llvm.getelementptr"(%arg13, %26) <{elem_type = f32, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr
    %28 = "llvm.load"(%27) <{ordering = 0 : i64}> : (!llvm.ptr) -> f32
    %29 = "llvm.add"(%21, %18) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64
    %30 = "llvm.getelementptr"(%arg20, %29) <{elem_type = f32, rawConstantIndices = array<i32: -2147483648>}> : (!llvm.ptr, i64) -> !llvm.ptr
    %31 = "llvm.load"(%30) <{ordering = 0 : i64}> : (!llvm.ptr) -> f32
    %32 = "llvm.fmul"(%24, %28) <{fastmathFlags = #llvm.fastmath<none>}> : (f32, f32) -> f32
    %33 = "llvm.fadd"(%31, %32) <{fastmathFlags = #llvm.fastmath<none>}> : (f32, f32) -> f32
    "llvm.store"(%33, %30) <{ordering = 0 : i64}> : (f32, !llvm.ptr) -> ()
    %34 = "llvm.add"(%19, %arg3) <{overflowFlags = #llvm.overflow<none>}> : (i64, i64) -> i64
    "llvm.br"(%34)[^bb1] : (i64) -> ()
  ^bb3:  // pred: ^bb1
    "llvm.return"() : () -> ()
  }) {gpu.kernel, gpu.known_block_size = array<i32: 32, 16, 1>, gpu.known_grid_size = array<i32: 16, 32, 1>, nvvm.kernel, nvvm.maxntid = array<i32: 32, 16, 1>} : () -> ()
  "gpu.module_end"() : () -> ()
}) : () -> ()
// -----// IR Dump After GpuModuleToBinaryPass Failed (gpu-module-to-binary) //----- //
module attributes {gpu.container_module} {
  llvm.func @matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64, %arg14: !llvm.ptr, %arg15: !llvm.ptr, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: i64, %arg20: i64) attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.constant(512 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i64
    %3 = llvm.mlir.constant(32 : index) : i64
    %4 = llvm.mlir.constant(16 : index) : i64
    %5 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %6 = llvm.insertvalue %arg14, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg15, %6[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.insertvalue %arg16, %7[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %9 = llvm.insertvalue %arg17, %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.insertvalue %arg19, %9[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %arg18, %10[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg20, %11[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = builtin.unrealized_conversion_cast %12 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %14 = llvm.insertvalue %arg7, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg8, %14[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %arg9, %15[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %arg10, %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %arg12, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %arg11, %18[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.insertvalue %arg13, %19[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = builtin.unrealized_conversion_cast %20 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %22 = llvm.insertvalue %arg0, %5[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.insertvalue %arg1, %22[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %24 = llvm.insertvalue %arg2, %23[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %25 = llvm.insertvalue %arg3, %24[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %26 = llvm.insertvalue %arg5, %25[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %27 = llvm.insertvalue %arg4, %26[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %28 = llvm.insertvalue %arg6, %27[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %29 = builtin.unrealized_conversion_cast %28 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<512x512xf32>
    %30 = builtin.unrealized_conversion_cast %0 : i64 to index
    %31 = builtin.unrealized_conversion_cast %1 : i64 to index
    %32 = builtin.unrealized_conversion_cast %2 : i64 to index
    %33 = builtin.unrealized_conversion_cast %3 : i64 to index
    %34 = builtin.unrealized_conversion_cast %4 : i64 to index
    %35 = llvm.extractvalue %28[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %36 = llvm.extractvalue %20[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %37 = llvm.extractvalue %12[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    gpu.launch_func  @matmul_memref_kernel::@matmul_memref_kernel blocks in (%4, %3, %2) threads in (%3, %4, %2) : i64 args(%3 : i64, %0 : i64, %4 : i64, %2 : i64, %1 : i64, %35 : !llvm.ptr, %36 : !llvm.ptr, %37 : !llvm.ptr)
    llvm.return
  }
  llvm.func @_mlir_ciface_matmul_memref(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %17 = llvm.extractvalue %16[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.extractvalue %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.extractvalue %16[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.extractvalue %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.extractvalue %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.extractvalue %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = llvm.extractvalue %16[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.call @matmul_memref(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15, %17, %18, %19, %20, %21, %22, %23) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> ()
    llvm.return
  }
  gpu.module @matmul_memref_kernel [#nvvm.target<triple = "nvptx-nvidia-cuda", chip = "sm_80">]  {
    llvm.func @matmul_memref_kernel(%arg0: i64, %arg1: i64, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: !llvm.ptr, %arg6: !llvm.ptr, %arg7: i64, %arg8: i64, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: !llvm.ptr, %arg13: !llvm.ptr, %arg14: i64, %arg15: i64, %arg16: i64, %arg17: i64, %arg18: i64, %arg19: !llvm.ptr, %arg20: !llvm.ptr, %arg21: i64, %arg22: i64, %arg23: i64, %arg24: i64, %arg25: i64) attributes {gpu.kernel, gpu.known_block_size = array<i32: 32, 16, 1>, gpu.known_grid_size = array<i32: 16, 32, 1>, nvvm.kernel, nvvm.maxntid = array<i32: 32, 16, 1>} {
      %0 = llvm.mlir.constant(512 : index) : i64
      %1 = nvvm.read.ptx.sreg.ctaid.x : i32
      %2 = llvm.sext %1 : i32 to i64
      %3 = nvvm.read.ptx.sreg.ctaid.y : i32
      %4 = llvm.sext %3 : i32 to i64
      %5 = nvvm.read.ptx.sreg.tid.x : i32
      %6 = llvm.sext %5 : i32 to i64
      %7 = nvvm.read.ptx.sreg.tid.y : i32
      %8 = llvm.sext %7 : i32 to i64
      %9 = llvm.mul %2, %arg0 : i64
      %10 = llvm.add %9, %arg1 : i64
      %11 = llvm.mul %4, %arg2 : i64
      %12 = llvm.add %11, %arg1 : i64
      %13 = llvm.mul %6, %arg3 : i64
      %14 = llvm.add %13, %arg1 : i64
      %15 = llvm.mul %8, %arg3 : i64
      %16 = llvm.add %15, %arg1 : i64
      %17 = llvm.add %14, %10 : i64
      %18 = llvm.add %16, %12 : i64
      llvm.br ^bb1(%arg1 : i64)
    ^bb1(%19: i64):  // 2 preds: ^bb0, ^bb2
      %20 = llvm.icmp "slt" %19, %arg4 : i64
      llvm.cond_br %20, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %21 = llvm.mul %17, %0 : i64
      %22 = llvm.add %21, %19 : i64
      %23 = llvm.getelementptr %arg6[%22] : (!llvm.ptr, i64) -> !llvm.ptr, f32
      %24 = llvm.load %23 : !llvm.ptr -> f32
      %25 = llvm.mul %19, %0 : i64
      %26 = llvm.add %25, %18 : i64
      %27 = llvm.getelementptr %arg13[%26] : (!llvm.ptr, i64) -> !llvm.ptr, f32
      %28 = llvm.load %27 : !llvm.ptr -> f32
      %29 = llvm.add %21, %18 : i64
      %30 = llvm.getelementptr %arg20[%29] : (!llvm.ptr, i64) -> !llvm.ptr, f32
      %31 = llvm.load %30 : !llvm.ptr -> f32
      %32 = llvm.fmul %24, %28  : f32
      %33 = llvm.fadd %31, %32  : f32
      llvm.store %33, %30 : f32, !llvm.ptr
      %34 = llvm.add %19, %arg3 : i64
      llvm.br ^bb1(%34 : i64)
    ^bb3:  // pred: ^bb1
      llvm.return
    }
  }
}


